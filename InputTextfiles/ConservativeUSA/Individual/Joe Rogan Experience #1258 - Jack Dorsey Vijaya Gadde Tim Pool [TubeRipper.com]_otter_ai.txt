All right. We're live ladies and gentlemen, to my left. Tim Tim Poole. Everybody knows and loves him. vija what is how do i pronounce your last video? Not vija Vidya Vidya Gatty. Got it and your position at Twitter is

I lead trust and safety, legal and public policy.

That's a lot. That's a lot. And Jack Dorsey. Ladies, gentlemen. First of all, thank you, everybody for doing this. Appreciate it. Thank you. It feels, feels Paulson, there's tension in the room. We're all loosey goosey just a few minutes ago, attention. Now everyone's like, Oh, this is really happening. Here we go. Before we get started, we should say because there were some things that people wanted to have us talk about. One that the Cash App is one of the sponsors of the podcast. It's been a sponsor for a long time. And also a giant supporter of my good friend, Justin runs fight for the Forgotten charity building wells for the pygmies in the Congo. This is very important to me, and I'm very happy that you guys are a part of that. And you are connected to that. I don't. That's mean, it's easy for someone to say that doesn't have an influence on the way we discuss things, but it doesn't. So if it does, I don't know. I'm

gonna mention to just because I don't want people to come out and freak out later actually have like, 80 shares in square, which isn't really that much. But, but it's something it is it is. So I don't want people to think, you know, whatever. You're the CEO of square, I think, right? Yep. Yeah. Well, they

want to cash out. And

the reason why we decided to come together is we had, I thought, a great conversation last time, but there was a lot of people that were upset that there was some issues that we didn't discuss or didn't discuss in depth enough, or they felt that I didn't press you enough. I talked to Tim, because, you know, Tim and I have talked before and he made a video about it. And I felt like his criticism was very valid. So we got on the phone, and we talked about it. And I knew immediately within the first few minutes of the conversation that he was far more educated about this than I was. So I said, Would you be willing to do a podcast and perhaps do a podcast with Jack? And he said, absolutely. So we did a podcast together, it was really well received, people felt like we covered a lot of the issues that they felt like I didn't bring up. And so then Jack and I discussed it, and we said, well, let's bring Tim on and then have vigia on as well. So that right? Yep, that's a hard one. Sorry. I'll get it right, I promise. But so we're here we go. Today, you know, Shaun Baker is he's a doctor who's a prominent proponent of the carnivore diet. His post was his account was frozen today. I just sent it to you, Jamie. Yeah, his account was frozen today, because of an image that he had, because he's a proponent of the carnivore diet. There's a lot of people that believe that this elimination diet, it's very healthy for you. And it's known to cure a lot of autoimmune issues with certain people, but some people ideologically oppose it, because they think it's bad for the environment, or you shouldn't eat meat, or whatever the reasons are.

This is huge in the Bitcoin community. Yes,

yeah. Well, it's for a lot of people that have autoimmune issues with particularly psoriasis. And arthritis is is a lifesaver. It's crazy. It's essentially, it's an autoimmune issue. So because he has a photo of a lion in a header eating a looks like a wildebeest or something like that, his account was locked for violating these rules, rules against graphic violence or adult content in profile images. That seems a little silly. And I wanted to just mention that right away now, whose decision is something like that, like, who decides to lock a guy's account out, because it has a nature image if you know, natural predatory behavior. On

this particular case, it's probably an algorithm that detected it and made some sort of an assessment. But as a general rule, how we operate as a company is we rely on people to report information to us. So if you look at any tweet, you can kind of pull down on that carrot on the right, and you can say report the tweet. And then you have a bunch of categories you can choose from and what you want to report. I think this one in particular, though, it's probably an algorithm.

So how does it does he have the option to protest that or to ask someone to review it? Absolutely.

And I'm guessing that people are already reviewing it, but there's a choice to appeal any action and that would go to a human to make sure that it is actually a violation of the rules? Or in this case, if it's not, then it would be removed.

Is that a violation of the rules? Image?

I don't think so. I don't think that that would be what we're trying to capture in terms of graphic images and an avatar. It's more about violence towards humans unless it was some sort of cruelty depicting walls or something like that. But this seems not the intention of the rule does

this this one of the reason why I wanted to bring this up immediately does this highlight a flaw in the system in that people can target an individual because with him, he's a, he, like I said, he's a doctor and a proponent of this carnivore diet. But he's also he ruthless in his condemnation and mocking of vegans, he does it all the time. And so then they get upset at him, and they can target posts and just report them in mass. And when they do that, then this becomes an issue.

I think this does reveal part of, you know, the challenges that we face as a global platform at scale. And this, I don't I don't know what happened in this case, sorry, it's hard for me to talk about it. But what I would say is that, it doesn't really matter if one person reports it, or 10,000, people report it, like we're going to review the reports and we're going to make an assessment. And we're never going to, you know, kick someone off the platform finally, and forever without a person taking a look and making sure that it's an actual violation.

Okay,

so at the put the mob reporting behavior does happen. Yeah, it does. It happens across the spectrum,

I'd have to assume it's going to be one direction, I can't imagine he would target vegans, but vegans would target him,

right? Well, he might. I mean, he doesn't. But is he the kind of guy who's

gonna want to report to vegans and get them banned from Twitter? Or is he gonna want to make fun of them, he's gonna make fun of them, they're going to target him to try and get him removed by exploiting the system that you guys have. It

may not be him, though, it could also be his followers. It's a really complicated world out there. So you don't want the motivations of why people mob report are different. And it's not always under someone's control.

We could easily even be other carnivore diet proponents who are just jerks that don't like him, because he's getting all the love. People are weird. Yeah, but it's just the idea, though, is that it does kind of highlight a bit of a flaw in that it's good that someone can like because you might see something awful, someone Daxing someone or something like that. And then you can take that and report it, and then people can see it and get rid of it and minimize the damage. That's done. There's

another big problem here. And that is the carnivore diet legitimately healthy. Is it a threat to your health? And if it is, is what is Twitter's responsibility in controlling that information? Right. So just to clarify, my my opinion is, if he wants to be a proponent for the carnivore diet, let him but you've got people on YouTube who are being direct for certain beliefs about certain health issues that I don't agree with. And so one of the risks then is, you know, we're coming towards a position where people think some ideas are better than others. Therefore, as a company, we're going to restrict access to certain information. You mean like anti Vaxxer? Exactly. So I guess I'm trying to say is, at what would you guys restrict someone from sharing in for like false information about vaccines that could get someone hurt?

That is not a violation of Twitter's rules? No,

I think, I mean, I'd be interested to hear your ideas around this. But our, our perspective right now is around this concept of variety perspective. Like, are we? are we encouraging more echo chambers and filter bubbles? Or are we at least showing people other information that might be countered to what they see? And there's, there's a bunch of research that would suggest that further and Bolton's or views, there's also research that would suggest that at least gives them a consideration about what their what they currently believe. So you guys, sorry, given the dynamics of our network being completely public, we're not organized around communities were not organized around topics. We have a little bit more freedom to show more of the spectrum of any one particular issue. And I think that's how we would we would approach it from the start. That said, we haven't really dealt much with misinformation more broadly across like, these sorts of topics. We've we've focused our efforts on elections, and well, mainly election trying to, you know,

YouTube is a different animal, you know, someone can really convince you that the earth is flat. If you're gullible, and you watch a 45 minute YouTube video, right now, it's kind of a different thing.

But I want to I wanted to just kind of get into that statement you made about misinformation and whether or not you'll police it.

So I think that the tough part of this is really in love to have a discussion about this is do you really want corporations to police? What's true and not true? Absolutely not. It's a really, really tough position. But you guys do that. We try not to do that. We don't want to do that when placed when your rules, but the places that we focus on is where we think that people are going to be harmed by this in a direct and tangible way that we feel a responsibility to correct now, in your

rules, Tim, what do you mean by that? That naming and misgendering dead naming and misgendering

that's a specific ideology that's unique to a very small faction of people in this world that you guys actually banned people for.

So the way I think of it is its behavior based. And I know you think of it as content and we can we can disagree on this point. But this is about why are you doing this to a trans person? Why are you calling them by this name when they've chosen to go by a different name, or why are you outing them in some way? What is your intent and purpose behind that?

Meeting and rapidly in the interest of clarity, I want to explain what Add naming means Right, right.

So that so a transgender individual changes their name when they transition, a dead name would be their birth name or the name they went by before the transition. So yes, my mom's probably

going what? And whenever the text what's a dead name? And

I will clarify to your rules specifically targeted misgendering. And naming,

I believe it's correct, right. So years ago, we we passed a policy that we call our hateful conduct policy, and that prohibits targeting or attacking someone based on their belonging and in any number of groups, whether it's because of their religion, or their race, or their gender, their sexual orientation, their gender identity. So it was something that's broad based is that you you can't choose to attack people because of these characteristics. But

you do have limits on what characteristics you police. Right? So you're not you're not banning people, but for targeted trans species, others, right? Well,

we have also general abuse and harassment rules, right, which says you can't engage in abuse and harassment on the platform.

But you can't designate someone but you can call them stupid.

Generally, I mean, if you created an account that only was there to call the same person, stupid 5000 times, we'd probably view that as the, you know, targeted, harass targeted harassment. It's

a function of the it's unfortunate behavior, because people with our system can do this in massive velocity. So let's ultimately silence you from a platform or just say, like, I give up, I don't want to deal with this thing. I'm

also there's so we can just get into all of the big examples. I mean, starting with Tim,

but can we just take a step back and try to level set what we're trying to do with our policies? I think it's worth Yes, yes. So as a as a high level, I personally, and this is my job to run the policy team, I believe that everyone has a voice and should be able to use it. And I want them to be able to use it online. Now, where we draw a line is when people use their voice, and use their platform, to abuse and harass other people to silence them. Because I think that that's what we've seen over the years is a number of people who have been silenced online because of the abuse and harassment they've received. And they either stop talking or they leave the platform in its entirety. If you look at free expression and free speech laws around the world, they're not absolute. They're not absolute. There's always limitations on what you can say. And it's when you're starting to endanger other people.

So so my question then is, when I was physically threatened on Twitter, you guys refuse to take down the tweet. And I showed up in Berkeley, and someone physically threatened me because they were encouraged to when I was in Venezuela, I was physically threatened by high profile individual 10,000 people tweeting at me, you guys do nothing. Right. So I guess there's the obvious question of Why does it always feel like your policies are going one direction politically, you say it's about behavior. You said it several times already. But I've already I've got tons of examples of that not being the case. And you will always be able to find those examples, examples where you guys were alerted multiple times, and did nothing like when Antifa doxxed, a bunch of law enforcement agents, some of the tweets are removed. But since September, this tweet is still live with a list of private phone numbers addresses yet Kathy Griffin, she's fine. The guy who threatened the lives of these kids in Covington, and said lock them in the school and burn it down. You did nothing. I mean, you got suspended it take his tweets down, was he banned for threatening the lives of kids? Absolutely not.

So again, we have and I'm, I'm happy to talk about all these details. We have our policies that are meant to protect people. And they're meant to enable free expression as long as you're not trying to silence somebody else. Now, we take a variety of different enforcement mechanisms around that. Sometimes you get warned, sometimes your your tweet is forced to be deleted. It's a very rare occasion where we will outright suspend someone without any sort of warning, or any sort of ability to understand what happened.

What did you guys do with Kathy Griffin when she was saying she wanted the names of those young kids were in the Magga hats at the Covington high school camp.

That's a that's a great example, Joe. So in that particular case, you know, our Daxing policy really focuses on posting private information, which we don't consider names to be private, we consider your home address, your home phone, your home phone number, your mobile phone number, those types of things to be private. So in that particular case, we took what I think now is probably a very literal interpretation of our policy. And so that that was not a Daxing incident.

Do you think that was an error?

I think that it was short sighted and given the context of what was going on there that if I was doing this all over again, I would probably ask my team to look at that through the lens of what was the purpose behind that tweet. And if the purpose was in fact, to identify these kids to either Dox them or abuse and harass them, which it probably was, then we should be taking a more expansive view of of that policy and including that type of content,

especially considering the fact they're minors, I would think that right away, that would be like the approach. So this is trial and error, sort of learn and move on with new information, sort of a deal? Absolutely.

We're gonna learn we're going to make a ton of mistakes. We're trying to do this, with hundreds of millions of accounts, all around the world, numerous languages, were going to make mistakes. Even if we get better. There will always be mistakes, but we're hoping to learn from those and to make ourselves better and to catch cases like Tim's or others, where we clearly may have made an error I am open to having those discussions. I'm not I'm sorry, I'm familiar with your specific cases. But I'd love to follow up with you and you really

want to see the tweet, we pull it up. So it's bi t.li/antifa, tweet all lowercase. This

is also an evolution and privatization as well. One of the things we've come to recently as we do, we do need to, we do need to prioritize these efforts, both in terms of policy enforcement, how we're thinking about evolving them, one of the things that we want to focus on as number one is physical safety. And this leads you immediately to something like Daxing. And right now, the only way we take action on a Daxing case is if it's reported or not, what we want to move to is to be able to recognize those in real time, at least in the English language, recognize those in real time through our machine learning algorithms, and take the action before it has to be reported. So we're focused purely right now on going after Daxing cases with our algorithms so that we can be proactive, that also requires a much more rigorous appeals process to correct us when we're wrong. But we think it's tightly scoped enough that impacts the most important thing, which is someone's physical safety. Once we learned from that we can really look at the the biggest issue with our system right now is all the burden is placed upon the victim. So we only act based on reports, we don't have a lot of enforcement, especially with with more of the more more of the takedowns that are run through machine learning and deep learning algorithm.

But if something is reported, a human does review it eventually. Or are there a series of reports that you never get to?

There's there's probably reports we don't I mean, we prioritize a queue based on severity, and the thing that will mark severity of something like physical safety or private information or not. So generally, we try to get through everything, but we have to prioritize that cue even coming in.

So if someone threatened the lives of someone else, you would you banned that account, would you tell them like, like, let's say someone tweeted three times, kill these people, I want them dead. Three times. Is that Yes, that's a violation. You didn't ban him, though.

And I don't know why. Jamie, that's, uh,

I don't know, I don't necessarily want to give out specific user names. Because then that people just point the finger at me and say, I'm getting these people banned. But, you know, during Covington, this guy said multiple times, to he wanted his followers to go and kill these kids.

Yeah, and we have to look at that. But we also have to look in the context. Because we also have I think we talked about this a little bit in the last podcast, but we we have gamers on the platform who are saying exactly that to their friends that they're going to meet at the game in the game tonight. And without the context of their relationship without the context of the conversation that we're having. We would take the exact same action on them incorrectly.

Yeah, absolutely. That I understand. I think in the case of Covington, though, this user was so high profile. He's a verified user, he's got something like 20,000 followers, and it was highlighted by numerous conservative media outlets saying, Wow, this guy's it's screenshotted. It's being shared. I mean, you had a Disney producer, like saying, a picture of a wood chipper with a body being thrown in it saying that's what he wanted to happen. You know? So I do know that some of these accounts got locked isn't the producer was doing that? Well, I'll clarify fact, check me on that. But that's the basically the conversation that was had. And there's a guy that Disney was he posted a picture from Fargo of someone being tossed in a wood chipper, and he says, I want all these Margaret kids, you know, done like this. You had another guy who specifically said lock them in the school, burn it down, said a bunch of disparaging things and then said if you see them fire on them, and he tweeted that more than once. And

that those accounts where those tweets were taken down. Those were violations of our rules.

That's I'm pretty sure it's actually illegal to do that. Right? It's to tell your any individual to commit a felony is a crime like,

right? Yeah, incitement of violence. Yeah. So I'm in many places, I

just have to wonder how like, I understand the context issue. But this is what this is what I talk what

scale too, though, right?

The time those accounts were actioned, they may not have been action the way you wanted to, to, but the tweets were forced to be deleted. And that account was short. I can penalty for that. So I understand that

kind of a penalty. Well,

again, as I said earlier, Joe, we don't usually automatically suspend accounts with one violation, because we want people to learn, we want people to understand what they did wrong and give them an opportunity not to do it again. And it's a big thing to kick someone off the platform. And I take that very, very seriously. So I want to make sure that when someone violates our rules, they understand what happened, and they're given an opportunity to, you know, get back on the platform and change their behavior. And so in many of these cases, what happens is we will force someone to acknowledge that their tweet violated our rules forced them to delete that tweet before they can get back on the platform. And in many cases, if they do it again, we give them a timeout, which is like seven days and we say look, you've done it again. It's a temporary suspension if you do, you're a mom. I'm totally a mom. Exactly. And your mom and If you do it again, then you're not. So it's kind of like, you know, three strikes sort of like baseball. And so in some of these cases that Tim's referencing, I have to imagine because these tweets were deleted, they are violations of our rules. People are upset that the account came back again and was allowed to say other things. But we did take action on those tweets they were violations of, and

then you have people like Milo, who was mean to a person and you delete you banned him permanently. There's more

than actually talking about it. Yeah, yeah, I'm happy to talk about Milo and actually brought the tweets because so

let's let's preface that by saying the point I want to make sure it's clear is that you had somebody who actively called for the death of people, I understand the context issue. Maybe he's talking about video games prototype, some scale, and scale. So this is a verified user. And

that's just the complexity in acting. There's not an excuse for why we don't do it in particular.

And then there are a lot of other examples to like, get into more egregious areas that I've prepared. So here we have someone with over 20,000 followers, he's verified numerous times incites his followers to commit a crime against these kids. The action taken against him is delete the tweets, you get a suspension, you get timeout, then you have people like Alex Jones, who berated a CNN reporter permanently banned, you get Miley INNOPOLIS, he was mean permanently banned. But

that's your impression. That's not what happened. Okay. I'm here to talk about the details if you want to Yes,

please. Let's do this one at a time. Let's start with Milo details with Milo. So

Milo had a number of tweets that violated our rules going back to 2014. But I'm going to talk about the final three in this concept. He claimed to be a Buzzfeed reporter in his bio, and he's a verified account. So that is impersonation. I'm not sure why he did that. He did do that. Well, Buzzfeed is a left wing thing. So he was doing parody, potentially, but our parody rules are very specific that if you have an account, that's me being a is a parody account, you need to say that it is a parody account. So

people, everybody who knows, Milo would know that he's not a Buzzfeed reporter

that people who don't know Milo will look at that verified account.

But it wasn't verified. After a while you removed his verification, he violated our rules, verification. So the viral via the verification was removed because of the BuzzFeed thing,

I believe. So I can I can confirm that, I believe so. He also docked someone he posted private information about an individual. So that was the second one. He tweeted to somebody else. If you were my child, I'd have dashed your head on Iraq and tried again, which we viewed as a threat.

Really? That's it, it was like he's saying, like your mom should have swallowed you. You know, it's like, you know, I'm saying he's like you're a mistake. That's a threat.

I understand why reasonable people would have different impressions of this. I'm just going through and telling you what they are just sort of have all the facts on the table, and then we can debate them. And then the last one, we found a bunch of things that he posted that we viewed as incitement of abuse or against Leslie Jones. So there's a bunch of them, but the one that I like to look at which really convinced me is he posted to doctored tweets that were supposedly by Leslie Jones, they were fake tweets. The first one said, white people are getting on my nerves like How can you call yourself human. And then the second one said, the goddamn slur for a Jewish person at Sony ain't paid me yet. Damn. Vic's nude better pay

up. So this was just a fake tweet that someone had photoshopped to, to to fake

fake tweets. And we know they were faked because we could still tell from the software that they were faked is you can't always tell.

So it is possible that he didn't know they were faked. It's possible someone sent it to him. And he didn't do his due diligence and looking it up. And

it is possible. But it was pointed out to him that they were fake because he left it on. And not only did he leave it on, he said don't tell me some mischievous internet rascal made them up exclamation point. So this on the context of a bunch of other things he was saying towards Leslie Jones on Twitter, I and my team felt that this was taken as a whole incitement of harassment against

her. Wasn't there another issue with multiple accounts that were connected to him?

There were a bunch of other issues on the background. But these are the three primary things that we looked at. In terms of the

other things that were in the background, weren't they multiple accounts that were connected to him? Like,

I think that I'm not sure about that. Joe? I think it was more that we found him to be engaging in coordinated behavior and inciting people to to attack Leslie Jones now

with a case like him. No, I'm just going to be honest, when I'm listening to those or listening to read those tweets out. They don't sound that bad, and they certainly don't sound as bad as calling for the death of a child who's wearing a maga hat throw him into a woodshop or the fact that that guy is still out there, tweeting and yet Milo's not Milo's initial, the whole thing stemmed from Other than the BuzzFeed thing stemmed from his legitimate criticism of a film, and he's, you know, he's a satirist, he was mocking this film, The

Daxing incident wasn't related Daxing.

And so why don't we? Why don't we all

agree that Daxing is something that Twitter should take action under percent, threaten people in real life. And I take an enormous amount of responsibility for that, because I fear daily for the things that are happening on the platform that are translating into the real world.

So Milo is a contentious figure, and there's certainly things you can pull up that I wouldn't agree with anything he did there. I think those are horrible. I think Joe brought up some really good points. But what about Chuck Johnson? Why was Chuck Johnson banned?

I don't have those details in front of me.

Chuck Johnson said that he was preparing something to take out DeRay Mckesson and in the in a journalistic context, people take this to mean he was going to do a dossier or some kind of hit piece on Deray is permanently banned. Am I understanding and it's been a long time since I've read this. There was some leaked emails, I think, from Nick Costolo, where he said, maybe it wasn't deck, I don't want to drag deck. I don't know who it was exactly. They said, I don't care. Just get rid of him. And he was off. So you have? And again, maybe there's some hidden contexts there. I don't know. But on the surface concern

is that this is always leaning towards the left. Oh, it absolutely is. And I'm,

I'm not even getting started. Yeah, I

can understand why you feel that way. I don't think that's true. I think we look at each individual instance of violations of our rules and try to make the best case that we can. And I'm not trying and I do think just to just to say, I do think we've failed in a couple of ways. And I want to admit that. Number one, we haven't done enough education about what rules are because a lot of people violate our rules. And they don't even know it, like some of the statistics that we've looked at, like for a lot of first time users of the platform, if they violate the rule once almost two thirds of them never violate the rules again. So we're not talking about like a bunch of people accidentally, like if they know what the rules are, most people can avoid it.

And most people, when they feel the sting of a violation, they go, Okay, I don't want to lose my rights to post

exactly, and then they're able to do it. So we have a lot of work to do on education. So people really understand what the rules are in the first place. The other thing we have to do to address these allegations that we're doing this from a biased perspective, is to be really clear about what types of behavior are caught by our rules, and what types are not and to be transparent within the product. So when a particular tweet is found to be in violation of our rules being very, very clear, like this tweet was found to be in violation of this particular rule. And that's all work that we're doing. Because we think the combination of education and transparency is really important, particularly for an open platform like Twitter. It's, it's just part of who we are, and we have to build it into the product.

I appreciate that your particular thoughts, though, on those examples that he described when he talking about someone saying he should throw these children into a wood chipper versus Chuck Johnson saying he should take this guy, he wants to prepare a dossier to take this guy out, or how do you say it?

He said something like, I'm going to take out DeRay Mckesson with he said, I'm preparing to take out there something like that I can't prepare

and I can understand it could be misconstrued as he was trying to assassinate him. Right. You could you could misconstrue it but not a direct threat. But the other one is a direct threat. One guy is banned for life, the other guy's still posed,

and we can, I'm happy to follow up, I just don't have all the shutdowns. And it's not about one thing. It's about a pattern in practice of violating rules. And we don't want to kick someone off for one thing. But if there's a pattern in practice, like there was for Milo, we are going to have to take action at some point because we can't sit back and let people be abused and harassed and silenced on the planet. Well, so.

So one really important thing that needs to be stated is that Twitter, by definition is a biased platform in favor of the left period. It's not it's not a question I understand, you might have your own interpretation. But it's very simple. Conservatives do not agree with you on the definition of misgendering. If you have a rule in place that specifically adheres to the left ideology, you by default are enforcing rules from a biased perspective. Let's

him there are a lot of people on the left who don't agree with how we're doing our job, either, for sure. And those people think that we don't take enough action on harassment, and we let far too much behavior go. And I think that's

a radical example, though. I mean, what he's talking about, I mean, in terms of generalities that in general things lean far more left, would you agree

to that? I don't know what that means. But in

this particular case, it's how the speech is being used, that this is a new vector of attack that people have felt that I don't want to be on this platform anymore, because I'm being harassed and abused, and I need to get the hell out.

Will people harass and abuse me all day and night? You don't do anything about that? I might my notifications permanently locked at 99 UVA worse than I do. I mean, you get substantially more followers. And I don't click the notification tab anymore, because it's basically just harassment. And I, even when so this is a really funny anecdote. I was covering the story in Berkeley. And someone said, if you see him attack him, like it was it was I'm paraphrasing, they said basically, to swing at me take my stuff steal from me, and Twitter told me after review was not a violation of their policy. Somebody made an allusion to me being a homosexual, and I reported that instantly gone. So when I shot so so for me, I'm looking I'm Like, well, of course, of course Twitter is going to enforce the social justice aspect of their policy immediately, in my opinion, probably because you guys have PR constraints. And you're probably nervous about that. But when someone actually threatens me with a crime and incites their followers to do it, and nothing got done, and I'm not the only one who feels that

way, that's a mistake. If someone acts in that manner, and threatens to hurt you, that's a violation of our rules, right? Maybe there was a mistake there. And I'm happy to go and correct that. And we can do it offline. So don't fear any sort of reprisal against you. But that's a mistake. That's not an agenda on my part, or in the team Spark,

would this be we don't make any PR constraints when it does not.

So why did you ban Alex Jones?

You want to get into that? Absolutely. Are you ready? For sure? All right. Oh, well, I've been ready for.

Well, let me say this, the reason I bring him up is that Oliver Darcy, one of the lead reporters, covering Alex Jones, and his content said on CNN, that it was only after media pressure, did these social networks take action? So that's why I bring him up specifically, because it sort of implies you are under PR constraints to get rid of him.

I think if you look at the PR, that's what I went through in that incident, it wouldn't be that we looked good. And you have and that's not at all why we took action.

You have to look at the full context on the spectrum here. Because one of the things that happened over a weekend is what Alex mentioned on your on your podcast with him. He was removed from the iTunes podcast directory. That was the that was the linchpin for him. Because it It drove all the traffic to what he said basically, zero. Immediately after that, we saw our peer companies, Facebook, Spotify, YouTube, also take action. We did not, we did not because we when we looked at our service, and we looked at the reports on our service, we did not find anything in violation of our rules. Then we got into a situation where suddenly, a bunch of people were reporting content on our platform, including CNN, who wrote an article about all the things that might violate our rooms, rules that we looked into. And we gave him one of the other warnings, and then we can get into the actual details. But yeah, we did not follow. We We resisted, just being like a domino with our peers, because it wasn't consistent with our rules and the contract we put in before our customers.

So what was it that made you ban them?

So there were three separate incidents that came to our attention after the fact that were reported to us by by different users. There was a video that was uploaded that showed a child's being violently thrown to the ground and crying. So that was the first one. The second one was a video that we viewed as incitement of violence. I can read it to you it's a little it's a little bit of a transcript. But But now it's time to act on the enemy before they do a false flag. I know the Justice Department's crippled a bunch of followers and cowards but there's groups there's grants juries, there's you called for it it's time politically, economically and judiciously and legally and criminally to move against these people. It's got to be dumb now, get together the people you know, aren't traders aren't cowards aren't helping their frickin bets, hedging their fucking bets like all these other assholes do and let's go, let's do it. So people need to have their and then there's a bunch of other stuff, but at the end, so people need to have their battle rifles ready and everything ready at their bedside. And you've got to be ready because the media is so disciplined in their deception.

So this is, you're saying that this is a call to violence against the media.

That's what it sounded like to us at the time. And there have been a number of incidents of violence against the media. And again, I take my responsibility for what happens on the platform and how that translates off platform very seriously. And that felt like it was an incitement to

violence. If he only tweeted the incitement to violence would have been fun. If he only only tweeted that trans posted that transcript saying your Battle Rifles ready, you wouldn't have deleted his account.

Again, context matters to him. It's not about one thing. So we'd have to look at the entire context of what's going on. So I'm

asking Was that was that egregious enough for you to say that alone? That wasn't? That wasn't that was number two. Right. Right. So then I guess the question is, what was the video context of the kid being thrown to the ground? Was it newsworthy?

We obviously didn't think so. And depicting violence against a child is not something that we would allow on the platform, even if it's news content. If it was, there are certain types of situations where if you were reporting on, you know, warzone, and things that might be happening, we would put an interstitial on that type of content that's graphic or violent, but we didn't feel that that was the context here.

Well, so here's a video that's been going around that was going around few, four or five weeks ago, the one where the girls were yelling at that big giant guy, and the guy punched that girl in the face and she was like, 11 years old. I saw that multiple times on Twitter. That was one of the most violent things that we're seeing this giant man punch this 11 year old girl in the face. And that was was that removed from Twitter?

I don't know. I would have to go see if anyone reported it to us.

I think one of the issues here is to is you

want me I get to the third one. So the third strike that we looked at was a verbal altercation that Alex got into with a journalist and in that altercation there, which was uploaded to Twitter, there were a number of statements using eyes of the rat, even more evil looking person, he is just scum. You're a virus to America and freedom smelling like a possum that climbed out of the rear end of a dead cow. You look like a possum that got caught doing some really, really nasty stuff in my view. So it was a bunch of that's really that's hilarious pattern in practice, but it was just horrible altercation that was posted on our blog. So so. So we took the totality of this, and been warned that we have rules against abuse and harassment of individuals. We saw this pattern in practice. One strike two strike three strikes, and we made a decision to permanently and

so that last one was on Periscope, is that what it was that he broadcast through?

I think it was originally on Periscope, but it was also reposted from multiple related accounts onto Twitter.

So we can we can agree with you when you say these things. Like you know, Alex said this sounds like a threat. He was berating this person saying awful things. But ultimately your judgement is the context. You say we have to pay attention to the context, we're just trusting that you made the right decision.

Well, I'm I'm giving you as much facts as I can give you here. And I think that this is the real hard part of content moderation at scale on global platforms. It's not easy, and I don't think Jack Araya would tell you that it's easy.

So preposterous volume you guys have to deal with. And that's one of the things that I wanted to get into with Jack when I first had him on. Because when my thought and I wasn't as concerned about the censorship, as many people were, my main concern was, what is it like to start this thing that's kind of for fun, and then all of a sudden, it becomes the premier platform for free speech on the planet Earth. So

it is that but it's also a platform that's used to abuse and harass a lot of people and used in ways that none of us want it to be used. But nonetheless, it happens. So and I think it's an enormous ly complicated challenge for any company to do content, moderation at scale. And that's something that we are sitting down thinking about, how do we take this forward? Because this is it doesn't

go so well. So let's let's take the other context. Now we've heard what you said why what Alex Jones did was bad. And now we can look at it this way. Oliver Darcy, who has on numerous occasions insulted conservatives recently on CNN called them gullible being sold red meat by Grifters repeatedly covers a story, I'm going to do air quotes because I think to an extent he is allowed to cover these stories. He keeps going after Alex Jones, he keeps digging through his history. Then he goes on TV and says we got him banned. Then Alex Jones confronts him in a very aggressive and meanwhile, and that's your justification for why I should say I inverted the timeline. Basically, you have someone who's relentlessly digging through stuff insulting you, you know, calling you names, sifting through your history, trying to find anything they can to get you terminated, going on TV, even writing numerous stories, you confront them and say you're evil, and you say a bunch of really awful mean things. And then you ban him, right?

And then you post that information all over the internet. Right? But you have a journalist

who recently went on TV and said CPAC is a bunch of gullible conservatives being fed red meat by Grifters, you can tell this guy's not got honest, an honest agenda. So what you have it to me it looks like the conservatives, to an extent probably will try and mass flag people on the left. But from an ideological standpoint, you have the actual you know, whatever people want to call it, sect of identitarian left that believe free speech is a problem that have literally shown up in Berkeley burning free speech signs. And then you have conservatives who are tweeting mean things, and the conservatives are less likely in, I think it's fair to point out less likely to try and get someone else banned, because they like playing off them. And the left is is targeting them. So you end up having disproportionate

a lot of assumptions and what you're saying, and I don't know what basis you're saying those things.

I mean, you have conservatives demanding free speech, and you have liberals, I shouldn't say liberals, you have what people refer to as the regressive left, calling for the restrictions on speech. You have these,

I don't know what those terms mean, to be honest with you. We have people on all sides of the spectrum who believe in free speech, and I believe that to be the case.

So your platform restricts speech, our

platform promotes speech, unless people violate our rules, and

a specific direction, in any direction. But uncle, I don't wanna say his name, the guy who calls for death gets a suspension, the guy who insinuates that gets a permanent ban. But

Tim, you're you're misinterpreting what I'm saying. And I feel like you're doing it deliberately. It's not about one particular thing. It's about a pattern and practice of violin pattern

and practice of banning only one faction of people and I recently published an article where they looked at 22 High profile bandings from 2015 and found 21 of them were only on one side of the cultural debate,

but I don't look at the political spectrum of people when I'm looking at their to you you have a bias AR

you're biased and you're you're targeting specific individuals because your rules support this perspective.

No, I don't agree with that. Well, so

can you be clear though, Unlike what rules support that specifically,

the easiest one is misgendering. Right? Because that's so clearly ideological, if you ask a conservative, what is misgendering, they'll say if someone is biologically male, and you call them, you know, a biological man, you hold them mushy, that's Miss gender as a conservative view, the progressive view is inverted. So now you actually have in your policies, a rule against the conservative perspective,

I have a rule against the abuse and harassment of trans people on our platform. That's what my role is, we just give context in the background as to why that is, and I brought some some research. So we obviously received a lot of feedback. So we don't make these rules in a vacuum. And just to be clear, we have a bunch of people all around the world to give us context and the types of behavior they're seeing how that translates into real world harm. And they give us feedback. And they tell us like you should consider different types of rules, different types of perspectives different, like, for example, when we try to enforce hateful conduct in our hateful conduct policy in your particular country, we are not going to know all the slur words that are used to target people of a particular race or particular religion. So we're going to rely on building out a team of experts all around the world who are going to help us enforce our rules. So in the particular case of misgendering, I'm just trying to pull up some of the studies that we looked at, but we looked at the American Association of Pediatrics and looked at the number of transgender youths that were committing suicide, it's an astronomical I'm sorry, I can't find it right now, in front of me, there's a really, really high statistic that's like 10 times what the normal suicide rate is, of normal teenagers. And we looked at the causes of what that was happening. And a lot of was not just violence towards those individuals, but it was bullying behavior, and what was what were those bullying behaviors that were contributing to that. And that's why we made this rule, because we thought, and we believe that those types of behaviors were happening on our platform, and we wanted to stop it. There are exceptions to this rule. We don't. And this is all this isn't about, like public figures. And there's always gonna be public figures that you're gonna want to talk about. And that's, that's fine. But this is about, are you doing something with the intention of abusing and harassing a trans person on the platform? And are they viewing it that way and reporting it to us, so that we take action. So

so I will just state I actually agree with the rule. And from my point of view, I agree that bullying and harassing trans people isn't entirely entirely wrong, disagree with it. But I just want to make sure it's clear to everybody who's listening. My point is simply that, you know, Ben Shapiro went on a talk show and absolutely refused. And that's his shtick, you know, and he's one of the biggest podcasts in the world. So if you have all of his millions upon millions of followers who are looking at this rule, saying, This goes against my view of the world, and it's literally 60 plus million in this country, you do have a rule that's ideologically bent. And it's true, you you did the research, you believe this? Well, then you have Ben Shapiro who did his research and doesn't believe it.

Yeah. And I relied on the American Association of Pediatrics and Human Rights Council and other

I'm sure he has his sources, too, for when he gives his statements. The point is, but

just wonder if they have that context. I mean, and that's, and that's where we have also felt it was just explaining the why behind a lot of

reasons. I would agree. And I think it's fine. You did research and you found this to be true. But we can't simply say Maybe Ben Shapiro and other conservatives who feel this way don't know, we have to we can't, you know, the point I'm trying to make is it's simply whether you believe it, but whether you justify it or not, is not the point. The point is you do you do have this rule, that rule is at odds with conservatives, period.

Well, I think I think that you're you're generalizing. But I think it is really important, as Jack said to the why behind these things. The why is to protect people from abuse and harassment on our

planet, I understand, but you essentially created a protected class if this is the case, because despite these studies, and what you know, these studies are showing, there's a gigantic suicide rate amongst trans people period. It's a 40%. It's outrageously large. Now, whether that is because of gender dysphoria with us because of the complications from sexual surgery, sexual transition surgery, whether it's because of bullying, whether it's because of this awful feeling of being born in the wrong gender, whether that all that is yet to be determined. The fact that they've shown that there's a large amount of trans people that are committing suicide. I don't necessarily think that that makes that makes sense in terms of people from someone's perspective, like Ben Shapiro, saying that if you are biologically female, if you were born with a double X chromosome, you will never be x y. If he says that, that's that's a violation of your policy. And this is you're creating a protected class to beat to be fair, targeted,

targeted at or targeting.

Press that opinion. So with the silly anti Don't express that opinion if he's doing in a manner that's targeted at an individual repeatedly repeatedly repeatedly and saying that okay,

but what about the intent? You know what's going on with Martina Navratilova right now? Martina natural of why can I say your last name? And I've never? I don't think I've ever said it. Martina inevitable to Lova is it Talofa Trillo. Anyway, epic world class legend tennis player who happened to be a lesbian is being harassed, because she says that she doesn't believe that trans women meaning someone who is biologically male who transitions to a female should be able to compete in sports against biological females. This is something that I agree with. This is something I have personally experienced a tremendous amount of harassment, because I stood up when there was a woman who was a trans woman who was fighting biological females in mixed martial arts fights and destroying these women. And I was saying, you just watch this and tell me this doesn't look crazy to you? Well, good. Well, my point is, you should be able to express yourself. If you say that you believe someone is biologically male, even though they identify as a female, that's a perspective that should be valid, mean that this is someone's someone's, this is, first of all, it's biologically correct. So we we have a problem in that, if your standards and your policies are not biologically accurate, then you're dealing with an ideological, you know, an ideological policy. And just because, I mean, I don't, I don't want to target trans people, I don't want to harass them I serve, I'll call anybody, whatever they want. Me, if you want to change your name to a woman's name and identify as a woman, I'm 100% cool with that. But by saying I don't think that you should be able to compete as a woman, this opens me up for harassment, and I never recorded any of it. I just don't pay attention to it. But

in going into, like MEGAN MURPHY, for instance, right, you can call that target harassment. If MEGAN MURPHY who was for those that don't know, she's a radical feminist who refuses to use the transgender pronouns. If she's in an argument with a trans person over whether or not they should be allowed in sports or in biologically female spaces, and she refuses to use their pronoun because of her ideology. You'll ban them.

Again, it depends on the context on the platform. And it's also what not banned permanently, like you get

one she was banned permanently. But let's say she was warned about what happened. She was explaining to me, what what did she actually do? My

understanding, and I don't have the tweet by tweet the way that I did for the others. But my understanding is that she was warned multiple times for misgendering, an individual that she was in an argument with, and this individual is actually bringing a lawsuit against her in Canada as well. So if

you have an argument between two people, again, you have a rule that enforces only one side of the ideology, and you've found only one of those people, we have

a rule that attempts to address what we have perceived to be instances of abuse or harassment. She

was ideology, right. But it's an ideology, right? If she's saying a man is never a woman, if that's what she's saying, and then biologically, she's correct, we obviously have a debate here, this is not a clear cut. This is not something like you could say water is wet, you know, this is dry, it's this is not like something you can prove. This is something where you, you have to acknowledge that there's an understanding that if someone is a trans person, we all agree to consider them a woman and to think of them as a woman to talk to them and address them with their preferred name and their preferred pronouns. But biologically, this is not accurate. So we have we have a divide here, we have a divide between the conservative estimation of what's happening. And then the definition. That's the liberal definition of it.

I think that's right, Joe. And I think what I'm trying to say is that it's not that you can't have those viewpoints. It's as if you're taking those viewpoints, and you're targeting at them at a specific person in a way that reflects your intent to abuse and harassment. What

if it's in the context of the conversation? What if she's saying that I don't think that trans women should be allowed in these female spaces to make decisions for women. And then this person's arguing and she says, a woman is biologically female, you are never going to be a woman she

responded with men aren't women, though. And that was her first in the series of events. That's what got her the suspension and the warning. That

was one of many tweets that were part of providing context. And that was actually the second second actually, strike is my understanding. But why is that a strike?

Yeah. Why is that a strike that,

but again, like it's the context of I don't, I don't have all the tweets in front of me there were like 10 or 12 tweets going back and forth. And my understanding is that in the context of all of those, she was misgendering a particular person, not that she was holding a bumper sticker. No, it wasn't it. I don't know. It

was. So you're having you're having an individual who is debating a high profile individual in her community, and she's expressing her her ideology of versus hers, and you have opted to ban one of those ideologies.

It's within the context of this conversation. This is this is what is being debated whether or not someone is in fact, a woman when they were born a male.

I understand that this is controversial. I do i Especially to a radical feminists, I understand why why people would not agree with the rule. But that being said, it is a rule on our platform. And once you're warned about the rule, to repeatedly post the same content, is also going to be a violation of our rules.

Right. But the rule, it's this seems like a good example of an ideologically based rule. If you're if she's saying that a man is never a woman, though, that is not in that context, harassment, that is a very specific opinion that she has that happens to be biologically accurate. Now, I don't, you know, I don't agree with targeting harassment on anybody and I targeted harassment on trans people or, or straight people or whatever, I don't I don't agree with it. I don't think you should do it. It's just it's not something I want to do. But in this context, what she's saying is not just her her expression, but it's accurate.

I think an important point is, if I tweeted to you, Joe, Joe, you are not a hamster. That's clearly not a violation of the rules. However, there are identify as a hamster. Well, no, it wouldn't be clear, because I know, I know, people who have specifically begun using insults of animals to avoid getting kicked off the platform for breaking the rules. certain individuals who have been suspended now use certain small woodland creatures in place of slurs. So they're not really insulting you and it's fine. But there are people who consider themselves trans species. Now, I'm not trying to belittle the trans community, by no means. I'm just trying to point out that you have a specific rule for one set of people. And there, there are people who have general body dysphoria, you don't have rules on that. There are people who have actually amputated their own arms, you don't have rules on that you have a very specific rule set. And in more importantly, in the context of a targeted conversation, I can say a whole bunch of things that would never be considered a rule break. But that one is which is ideologically driven.

Yeah, thank you for the feedback. I mean, we're we're, again, always learning and trying to understand different people's perspectives. And all I will say is that our intent is not to police ideology. Our intent is to police behaviors that we view as abuse, movement, harassment, and I hear your point of view, and it's something that I'll definitely discuss with my team.

And even in this case, it would it wasn't just a going against this particular rule, but also things that were more ban evasive as well, including taking a screenshot of the original tweet reposting it, which is against our terms. Well, that sounds like it's more reactions.

It sounded like a protest against your rule. But I understand you got banned for it.

But people can protest any one of our rules. We can't We can't like let them do that.

No, no, I agree. I understand. You're saying but I just want to make sure I point out she was clearly doing it as an effort to push back on what she viewed as an ideologically driven rule.

Well, this is the problem is this is a real debate in the LGBT community. This is a debate where there's a division, and there's a division between people that think that trans women are invading biological female spaces and making decisions that don't benefit these biological females cisgender, whatever you want to call them. This is an actual debate. And it's a debate debate amongst progressive people amongst left wing people. And it's a debate amongst liberals. This is I mean, I would imagine the vast majority of people in the LBGT community are in fact, on the left. And this is one example of that. So you have a protected class. That's having an argument with a woman who feels like there's an ideological bent to this conversation that is not not only not accurate, but not fair. And she feels like it's not fair for biological women. The same as Martina. Well,

I'll take this to its logical conclusion, I got sent a screenshot from somebody, and maybe it's faked. I think it was real. They were having an argument with someone on Twitter and responded with dude, comma, you don't know blah, blah, blah. And they got a suspension and a lockout had delete the tweet, because the individual using a cartoon avatar with a eight with the name, which apparently was Sam reported it and said that I'm transgender, and he's calling me dude, and the dude and the Twitter user actually got a suspension for it so I can understand mistakes happen. But when you have a rule that's like that, there's colloquial terms that are like man, come on. Don't say that

dude is like we say like, like I asked you guys, when you were going to take a photo in front of this thing. I said, guys, but I included you

and I didn't. I wasn't offended. You reported you for it.

Thank you. Yeah, it's it's tricky. But in this case of MEGAN MURPHY, that's her name, right? Yeah. Yeah, I did. That doesn't make any sense to me. That seems like she should be allowed to express herself in this. This is not being she's not being mean. By saying a man is never a woman. This is a perspective that that is scientifically accurate. And that's that's part of the problem. I

just don't want to run into beating a dead horse. So I think I want to, it's

a really important thing to go over all the nuances of this particular subject, because I think that one in particular highlights this idea of where the problems lie and having a protected class and

be compassionate. We have a lot of protected classes, gender, race, nationality, like these are the protected

classes, not for white people. When you say gender or race, when it's not

all protected categories, so you can't attack someone for their belonging to a particular race or particular religion. Well, you

can mock white people ad nauseam, it's not a problem, it doesn't get it doesn't get removed.

I'm not talking about mocking, I'm talking about abusing and harassing. But I mean, if you mock

a black person in the same way, it would be considered targeted racism.

Again, it's about targeted harassment on the platform. But well,

what is targeted harassment? I mean, but when you're okay, like, if you have what is racism? is racism only mean there's this progressive perspective of racism, that it's only possible if you're from a more powerful class, so when punching down, that's the only racism I don't think that makes any sense. I think racism is looking at someone that is from whatever, whatever race and deciding that they are, in fact, less or less worthy, or less valuable, whatever it is, that that takes place, across the platform against white people. Now, I'm not saying white people need to be protected. I know it's easier being a white person in America, it's a fact. But it's hypocritical. To have a policy that only distinguishes you can make fun of white people all day long. But if you decide to make fun of Asian folks, or you know, fill in the blank, that is racist, but making fun of white people isn't and it doesn't get removed. There are tons of tickling about Sarah Jiang from the New York Times. That's, uh,

well, I can actually explain that one, please do that was my understanding is that you guys started banning people, official entities policies around 2015. And most all the tweets you made was prior to that. And so you didn't enforce the

old tweet. So our hateful conduct policy, Joe, just to be clear, is is across the board, meaning like, it doesn't just protect women protects men and women, it protects all races, it doesn't matter. And this is how the law is set up in the United States, right? You can't discriminate against white men, you can't discriminate against black men like those are the laws, right? Like that's the structure it is it doesn't it doesn't take into consideration. So if

someone says something about white people and mocks white people on Twitter, what do you do about that? If it's targeted harassment targeted at a person? So just white people in general, if you say something about white people in general, it's not an issue that Well,

I mean, we focus on targeted harassment, which is behavior that is targeted against an individual who belongs to that class, okay? Because if you try to police every opinion that people have about different races or religions, obviously, that's a very different story. So this is about if you target that to somebody who belongs to that class. And that's reported to us, that is a violation of our rules. And so in the Sarah Jiang case, a lot, we did see many tweets of that nature that were focused on people who are white or men. And our rules in this area came into effect in 2015, which was our hateful conduct policy. And a lot of those tweets were from a time period where those rules weren't

enough. And in her defense, she was actually supposedly responding to people that have you don't believe that come on

over three years. And she's tweeting blankets. Yeah, sure, sure. But so I will say to obviously, I've done

my one point. So in that case, there were tweets from before the rules went into effect and tweets from after the rules went into effect. And we did take action on the tweets from after the rules went into she's also

pretty young. But yeah, so I

want to point. Yeah, she's in her 20s. Yeah,

so we're talking about something that might have happened eight years ago. Right.

Right. So 20, it was like 2011 to 13. But I do want to point this out. Before coming on. I've obviously did not I did a decent amount of research. I searched for slurs against white people, black people, Latinos, and I found copious, just just tons and tons of them. Now, they don't go back up most of what I found and go back to Fox, it does seem like you guys are doing your best. But there's a lot and it targets white people, black people, Jewish people, it's everywhere. And I can I can I can understand that you guys, you got hundreds of millions. But let's let's let's let's try another subject just

just to address that point. And I think Jack talked about this a little bit like this is where right now we have a system that relies on people to report it to us, which is a huge burden on people. And especially if you're happen to be a high profile person and to me you would you would understand this, you're not going to sit there and report every tweet and Joe understand this. Like it's not worth your time. You're not going to go through tweet by tweet as people respond to you and report it. People tell us this all the time. This is where we have to start getting better at identifying when this is happening, and taking action on it without waiting for somebody to tell us it's

using an algorithm though do you not In this context, I mean, it seems to me that there's a lot of people that say things in humor, you know, they are

slurs within particular communities, which is perfectly reasonable. Right? Right. So yes, there is a danger of the algorithm is missing context. And that's why we we really want to go carefully into this. And this is why we've scoped down first and foremost, to Daxing, which is, at least first hit our number one goal, protecting physical safety, like making sure that nothing done online will impact someone's physical safety offline on our platform in this case, the second is that there are patterns around Daxing that are much easier to see, without having the context there are there are exceptions, of course, because you could docs, someone's public, you know, representatives public office, phone number and email address. And the algorithm might catch that not have the context that this is a US representative. And this information is already public. So

essentially, this just it highlights how insanely difficult it is to monitor all of these posts. And then what is the volume? Like? What are we dealing with? Like, how many posts do you guys get a day,

hundreds of millions of posts a day?

And how many human beings are manually reviewing any of these things?

I don't have that that number a lot.

A lot. 1000s, hundreds of 1000s? How many employees? You guys have we have 4000

employees around

the world? That's it? Yeah,

we have. We have 4000 employees. The reason?

That's crazy, though, but stop and think about that 4000 People that are monitoring hundreds of millions of tweets, and

we have a we have a we have a small team who's monitoring tweets, and some of them are employed by us. Some of them are contractors throughout throughout the world. So 4000 employees, total 4000 employees who are engineers who are designers who are lawyers, so

the number of people actually monitoring tweets is probably less than 1000.

Well, the reason we don't give out specific is we need to scale these dynamically, right? If we see a particular event within a within country, we might hire 100 more people on contract to deal with it, right. Whereas they may not be full time and with us the entire time,

they have the ability to take down tweets, they have they have the so

as we get reports, it goes into a queue. And those are ranked by severity. And then we have people who look at our rules and look at the look at the tweets and look the behavior and the context around it. And they have the ability to go down that enforcement spectrum, that video talked about one, make people log in, read why it's a violation over tweet and delete it to temporary suspensions. And finally, a permanent suspension, which is the absolute last resort, which we ultimately do not want to do. We want to make sure that our rules are also guided towards incentivizing more healthy conversation and more more participation. So

So let me ask you, the rules you have are not based in US law, right? US law doesn't recognize restrictions on hate speech, it's considered free speech. So if you want to stand on a street corner and yell the craziest things in the world, you're allowed to, on your platform, Twitter, you're not allowed to. So even in that sense, alone, your rules do have an ideology behind them. I don't completely disagree. I think, you know, I don't want harassment. But the reason I bring this up is getting into the discussion about democratic health of a nation. So I think it's, it can't be disputed at this point that Twitter is extremely powerful in influencing elections. You know, I'm pretty sure you guys published recently a bunch of tweets from foreign actors that were trying to meddle in elections. So even you as a company recognize that foreign entities are trying to manipulate people using this platform. So I there's a few things I want to ask beyond this. But if wouldn't it be important then to just as at a certain point, Twitter become so powerful in influencing elections and giving access to even the President's tweets, that you should allow people to use the platform based under the norms of US law, First Amendment free speech, the right to expression on the platform, this is becoming too much of a, it's becoming too powerful, and how our elections are taking place. So even if you are saying, well, hate speech is our rule. And a lot of people agree with it. If at any point, one person disagrees, there's still an American who has a right to this, you know, to access to the public discourse. And you've essentially monopolized that and not completely, but for the most part. So isn't there some responsibility on you to guarantee at a certain extent, less regulation happen? Right? Like, look, if you if you recognize foreign governments are manipulating our elections, Then shouldn't you guarantee the right to an American to access this platform to be involved in the electoral process?

I'm not sure I see the the the tie between those things, but I will address one of your points, which was we're not we're a platform that serves the world. So we're a global 75% of the users of Twitter outside of the United States. Right. So we don't apply laws on just one country. When we're thinking about it. We think about how do you have a global standard that can meet over the threshold of as many countries as possible, because we want all the people in the world to be able to participate in

the conversation, and also meet elections, like the Indian election coming up as well. Right.

And I'm my understanding is you're also accused of being biased against conservatives in India recently. There was a report on that, as well, as you held up a sign that said something offensive about the Brahmin. Yeah. So in that sense, even in other countries, you're accused of the same things that you're being accused of by American conservatives. I

think that the situations are very, very different. And I don't think that that the ideologies in play are the same at all.

Well, so the reason I bring can we clarify that?

I am not sure what you're talking about. But we we did have our vice president public policy, testified in front of Indian parliament a couple of weeks ago, and he was they were really focused on election integrity and safety, and abuse and harassment of women and political figures and the likes. So my,

my concern, I guess, is I recognize you're a globe, you're a company that serves the world. But as an American, I have a concern that the democracy I live in the Democratic Republic, I'm sorry, and the Democratic functions are healthy. One of the biggest threats is, you know, Russia and Russia, Iran, China, they're trying to meddle in our elections using your platform. And it's effective, so much so that you have actually come out and removed many people. You know, Covington was apparently started by a companies in Brazil. You know, the Covington scandal where this fake news goes viral, was reported by CNN that it was a it was a dummy account, they were trying to prop it up. And they were pushing out this out of context information. So they do this, they use your platform to do it, you've now got a platform that is so powerful in our American discourse, that foreign governments are using it as weapons against us. And you've taken a stance against the laws of United States. I don't mean like against like you're breaking the law. I mean, you have rules that go beyond the scope of the US, which will restrict American citizens from being able to participate. Meanwhile, foreign actors are free to do so so long as they play by your rules. So our elections are being threatened by the fact that if there's an American citizen, who says I do not believe in your misgendering policy, and you banned them, that person has been removed from public discourse on Twitter, right, but they

don't get banned for saying they don't agree with it. For sure, specifically, violating it by targeting an individual let's

say in protest, an individual repeatedly says no, I refuse to use your pronouns in like Meghan Murphy's case, and she's Canadian, so I don't want to use her specifically, the point I'm trying to make is at a certain level, there are going to be American citizens who have been removed from this public discourse, which has become so absurdly powerful foreign governments weaponize it, because you have different rules than the American country has.

So just to be clear, my understanding, and I'm not expert on all the platforms is that foreign governments use multiple, multiple different ways to interfere in elections. And it's not limited to our platform, nor wasn't limited to social media, but the President is our major, right president is on a lot of different platforms as as the White House,

I think it's fair to point out the media coverage of his Twitter account is insane. And they run new stories every time he tweets that and certainly

undeniable, I'm just pointing out that there are a number of different avenues for this, and individuals have choices and how they use the platform. So they'd

have other platforms, but he uses Twitter

almost exclusively. And what I'm trying to bring up is that if Twitter refuses to acknowledge this problem, you're facing regulation, I don't I don't know if you care about that. But at a certain point, which which problem, if you're going to restrict American citizens from participating in a platform where even the President speaks, and it's essentially you have a private, privately owned public space, if I could use an analogy that would be most apt. And you've set rules that are not recognized by the US. In fact, when it came to a supreme court hearing, they said hate speech is not a violation, it's actually protected free speech. So there's actual odds. So there might be someone who says I refuse to live by any other means than what the Supreme Court has set down. That means I have a right to hate speech, you will ban them. That means your platform is so powerful, it's being used to manipulate elections, and you have rules that are not recognized by the government to remove American citizens from that discourse. So as a private platform, you become too powerful to not be regulated if you refuse to allow people free speech.

But I'm trying to pick apart the connection, I think. So. Yes, we do have an issue with foreign entities and misinformation. And this is a extremely complicated issue, which we're just beginning to understand and grasp and take action on. I don't think that issue is solved purely by not being more aggressive on something else that is taking people off the platform entirely as well, which is abuse and harassment. It's a cost benefit analysis, ultimately, and our rules are designed again, and you know, they don't always manifest this way in the outcomes, but in terms of what we're trying to drive is opportunity for every single person to be able to speak freely on the platform and that's

absolutely not true. You don't allow hate, love hate speech. So free speech is not on your platform, I

should speak for everyone that create the opportunity for everyone to speak on our service, unless they've Alright, it's hate speech, right. And then in part of that the recognition that we're taking action on is that when some people encounter particular conduct, that we see them wanting to remove themselves from the platform completely, which goes against that principle of enabling everyone to speak or giving people the opportunity to speak are so rules are focused on the opportunities presented. And we have particular outcomes to make sure that those opportunities are possible. Let's let's

separate the first the point I made about foreign governments was just to explain the power that your platform holds, and how it can be weaponized. We'll separate that now, when Antifa shows up to Berkeley and bashes a guy over there with a bike lock, that is suppressing his speech, right? That's an act of physical violence. However, when Antifa links hands and blocks a door so that no one can go to an event, that is also legally allowed, right? So what you're saying is that if someone is engaging in behavior, such as going on Twitter and shouting someone down relentlessly, that's something external to what happens in in the world under the US government, I am allowed to scream very close to you, and not let you speak in public. But on Twitter, you don't allow that. So there's a dramatic difference between what Twitter thinks is okay, and what the US government thinks is okay, how our democracy functions and how Twitter functions. The issue I'm pointing out, is that we know Twitter is becoming extremely important in how our public discourse is occurring, how our cultural culture is developing, and who even gets elected. So if you have rules that are based on a global policy, that means American citizens who are abiding by all of the laws of our country are being restricted from engaging in public discourse, because you've monopolized it. Can I

counter that, though, because these foreign governments are restricted by the same rules. So if they violate those same rules, they will be they will be removed, play within those rules, they can participate in the discourse, even if they are just trying to manipulate our elections. On the other hand, if the people that are on the platform, play by those rules, they can also counteract

unless their ideology goes in line with US law and is legally allowed, as opposed to what you allow. So foreign governments can can absolutely keep making new accounts and keep botting and keep manipulating. They can even post things that will go viral, and they get banned and not care, right. But a private American citizen can say, Here's my opinion, I refuse to back down. So you will ban him. So we can see that at a certain point, you have your Twitter is slowly gaining, in my opinion, too much control from your personal ideology based on what you've researched what you think is right over American discourse, if you if Twitter and that's kind of my opinion, I'm not a lawmaker. But I would have to assume if Twitter refuses to say in the United States, you are allowed to say what is legally acceptable period, then lawmakers only choice will be to enforce regulation on your company.

Actually time I spent quite a bit of time talking to lawmakers as part of my role as head of public policy, spent a lot of time in DC, I want to say that Jack and I have both spent a lot of time in DC. And I think from the perspective of lawmakers, they across the spectrum are also in favor of policing, abuse and harassment online and bullying online. Well, it's those are things that people care about, because they affect their children if they affect their communities, and they affect individuals. And so I don't think that as a private American business, we can have different standards than what an American government owned corporations or American government would have to institute. Those are two different things American, and I understand your point about the influence. And I'm not denying that certainly, Twitter is an influential platform. But like anything, whether it's the American law, or the rules of Twitter, or the rules of Facebook, or walls of any platform, there are rules, and those rules have to be followed. So it is your choice, whether to follow those rules and to continue to participate in a civic dialogue and choice to not do that.

Absolutely. You've monopolized public discourse to an extreme degree and you say my way or the highway, we are facing

Tim, we haven't monopolize it. There are many different avenues for people to continue to have a voice. There are many different platforms that offer that we are largely influential. And I'm not trying to take away from that. And we're a very important one, you

don't need to be the most important. It's just that you are extremely important. And that's and that's a compliment. Twitter has become extremely powerful. But at a certain point, you should not have the right to control what people are allowed to say no private, or look, I'm a social liberal. I think we should regulate you guys, because you are unelected officials running your system, the way you see fit against the wishes of a democratic republic. And there are people who disagree with you are being excised from public discourse because of your ideology that terrifies me. And we can take it one step further.

Just Just so I understand. So are you suggesting that we don't have any policies around abuse and harassment on the platform? I'm I'm trying to understand what what it is you're saying, because I'm not I'm not sure I'm following you. So you don't think we have any rules about abuse and harassment. So even the the threats that you received that. But you mentioned a number of threats that you receive, and you're quite frustrated that we hadn't taken action on, you think we shouldn't have rules that

I'm frustrated because of the hypocrisy, I'll say, when I, when I see, I see the flow of One Direction. And then what I see are Republican politicians who in my opinion, are just too ignorant to understand what the hell's going on around them. And I see people burning signs that say free speech, I see you openly saying, we recognize the power of our platform, and we're not going to abide by American norms. I see the manipulation of Twitter for in violation of our elections. I see democratic operatives in Alabama, waging a false flag campaign using fake Russian accounts. And the and the guy who runs that company has not been banned from your platform, even after it's been written by the New York Times he was doing this. So we know that not only are people manipulating your platform, you have rules that remove honest American citizens with bad opinions who have a right to engage in public discourse. And it's like you recognize it, but you like having the power? I'm not quite sure at what point to

get back to my point. So you believe that Twitter should not have any rules about abuse and harassment or any sort of hate speech on the platform

that that's your personal that's that's that's extremely reductive. I don't know that maybe maybe too simplistic. The point I'm trying to make is, but

But you ain't you're trying to make your you're asking us to comply with the US law that would criminalize potential speech and put people in jail for it. And you're asking us to enforce those those terms? Well,

I mean, if you incite death, you will, it's a crime, you can vote you can go to jail for that. So at the very least you could you like when you when you have people on your platform who've committed crime, you don't ban them? I say, well, that's really weird. And then when you have people on your platform, who say a bad naughty word, you do ban them, I say, well, that's really weird. I mean, I've seen people get banned for for tweeting an end to you, I understand what they're trying to do. And they tweet letters that you check, but they get suspended for it, they get a threat, you know, like you can't let's let's talk about learn to code. What

do you what do you mean by that? So, so there

are people who know that they can tweet a single letter, and the next person knows what letter they need to tweet. You see, I'm saying so you'll see, you know, one user will say, and the next user will put an eye the next user really? Yes. And so they get suspended for doing so. And these are these are the people who are trying to push the buttons on the rules, right? They get suspended for that. Absolutely. So because I think here's the thing, I think I think your team understands what they're doing. However, you get really dangerous territory. If someone someone accidentally tweets and and you assume they're trying to engage in a Harassment campaign, which is why I said, let's talk about learn to code.

But we do we do look at coordination of it, of accounts.

We're not, we're not direct messages.

I don't know about direct messages. But until you read direct messages, we don't read direct messages, we

don't read them unless someone reports a direct message to us that

they have received. And so you read their direct message that they send to you. So

if if you have a direct message, and someone says something terrible, and then like you receive a death threat and your report that to us, then we would read it, because you've reported it to

Does anyone in the company have access to direct messages other than that?

Only in the context, again, of reviewing reports that are not accessible? Not to my knowledge, I don't know what you mean, like we're not accessible? We're not reading them?

Is it possible that someone could go into Tim's direct messages and just read his direct messages? I don't think so. So if Tim writes an N, and I write an i, and Jamie writes a G, can you go into our direct messages and say, Hey, let's fuck with Jack. And we're gonna write this stuff out. And we're going to do it. And let's, let's see if they ban us. You can't read that?

I don't think so.

So if that's the case, I want to know if there was a concerted effort. And

I think what he's saying is like, if we if we do see those train of replies, and that is that is coordination.

You know what people are doing? Right? The question is, how

do you prove it? Well,

I think beyond the end, like, you know, the first person who put the letter you can't prove he did it, but everybody else you kind of can, but I don't think we would. Well, I've look, I can say this, I've been sent numerous screenshots from people screenshots can be faked. I recognize that but I, I've seen people actually tweet, and then I've seen the tweet, follow right after one one letter. Yeah, someone tweeted at you, someone decently high profile, a big YouTuber tweeted an end at you and then got like a 12 hour suspension. But let's talk about learn to code. Right? And why are people being suspended for tweeting, hashtag learn to code? We

did some research on this. Yes,

we did some research on this. So there was a situation I guess about a month ago or so, where a number of journalists were receiving a variety of tweets, some containing learn to code, some containing a bunch of other coded language that was wishes of harm. These were 1000s and 1000s of tweets being directed at a handful of journalists. And we did some research and what we found was A number of the accounts that were engaging in this behavior, which was tweeting at the journalists with this either learn to code or things like day of the rope and other coded language, were actually banned evasion accounts, that means accounts that had been previously suspended. And we also learned that there was a targeted campaign being organized off our platform to abuse and harass these journalists. That's not true.

See, here's the thing, an activist who works for NBC wrote that story, and then lobbied you, you issued an official statement. And then even the editor in chief of The Daily Caller, got a suspension for tweeting learned Dakota the day at The Daily Show.

So I have never talked to anybody from NBC about this issue. So I'm no

so they report it don't misrepresent me, they report it in the narrative goes far and wide amongst your circles, then all of a sudden, you're seeing high profile, conservatives tweeting a joke or getting suspensions.

So again, some of these tweets actually contained death threats, wishes of harm, other coded language that we've seen to mean, death to journalists. So it wasn't about just the learn to code, it was about the context that we were doing.

That's just not true. The editor in chief of The Daily Caller was suspended for tweeting nothing but hashtag learn to code.

So Tim, can I can I finish what I'm saying? Yeah, so we were looking at the context. And what was happening is there were journalists receiving hundreds of tweets, some had death threats, some had wishes of harm, some just learned to code. And in that particular context, we made a decision, we consider this this type of behavior, but dogpiling, which is when all of a sudden individuals are getting tons and tons of tweets at them, they feel very abused or harassed on the platform.

We pause this because this was super confusing for people who don't know the context. The learn to code thing is in response to people saying that people that are losing their jobs like coal miners, and truck drivers and things like that could learn to code. This was it was almost like ingest initially, or if it wasn't ingest initially, it was so poorly thought out as a suggestion that people started mocking it. Right? Correct. So

the first stories that came out, were simply like can miners learn to code? No miners, right? And the hashtag learn to code is just a meme. It's not even necessarily a conservative one that you will see more conservatives using it was

people are using it to mock how stupid the idea of taking a person who's on educators in their 50s Who should learn some new form of vocation, and then someone says learn to code. And so then other people when they're losing their job, or when something's happening, people would write learn to code because it's a meme. Well,

not even necessarily I would I would just characterize learn to code as a meme that represents the elitism of modern journalists and how they target certain communities with disdain. Okay, so to make that point, there are people who have been suspended for tweeting something like I'm not too happy with how you know BuzzFeed reported the story, hashtag learn to code, right? Making representation of these people are snooty elites who live in ivory towers. But But again, you know, this is a meme that has nothing to do with harassment. But you know what, some people might be harassing somebody who might tweet it, why would we expect to see even still today, I'm still getting messages from people with screenshots saying, I've been suspended for using a hashtag. And the editor in chief of The Daily Caller. Right. He he took he quote, tweeted a video from The Daily Show with hashtag learn to code. And he got a suspension for it. So why

why learn to code? Why is that alone? So egregious, and I don't think it is so egregious, just something rendered stuck in an algorithm. No, it was a, again, a specific set of issues that we were seeing, targeting a very specific set of journalists. And it wasn't just the learn to code, it was a couple of things going on. A lot of the accounts, tweeting, learn to code were banned debaters, which means curiously been suspended. A lot of the accounts had other language in them, or have tweets out other language like day of the brick day of the rope, oven ready. These are all coded meanings for violence against people. And so and the people who are receiving this, we're receiving hundreds of these, in what appeared to us to be a coordinated Harassment campaign. And so we were trying to understand the context of what was going on and take action on them. Because again, I don't know, Joe, if you've ever been the target of dogpiling event on Twitter, but it is not particularly fun, when 1000s of people or hundreds of people are tweeting at you and saying things and that's can be viewed as a form of harassment. And it's not about the individual tweet, it is about the volume of things that are being directed, I understand. And so in that particular case, we made the judgment call and it is a judgment call to take down the tweets that were responding directly to these journalists that were saying learn to code even if they didn't have a wish of harm specifically attached to them because of what we viewed as coordinated attempt to harass them and again, like I was saying some of the other signals and coded language and we were worried that learn to code was taking on a different meaning understanding in that particular context.

So but in in the of itself though it still seems like there's alternative meanings to learn to code. It still could be used as Tim was saying to mark a liberal. Elite snooty picture

to pass. Yes, absolutely. I agree with you. So it's really about the context of what was happening in that situation and all those other things. I think in a very different situation, we would not take action on that. Okay.

But doesn't that seem like you're, you're throwing a blanket over a very small issue. I think learning to code in itself is very small, the blanket is cast over racism, the blanket is cast over this, all the other horrible things that are attached to it. But the horrible things that are attached to it, the real issue, this learn to code thing is kind of a legitimate protest, in people saying that these miners should learn to code that's kind of preposterous.

The first articles weren't mean, it was just it learned to code kind of identified, you have these journalists who are so far removed from Middle America, that they think you can take a 50 year old man who's never used a computer before and put them in a row. The stories I think were legitimate, yes, the point more so it was a meme. The hashtag, the idea of learn to code condenses this idea. And it's easy to communicate, especially when only have 280 characters, that there is a class of individual in this country. I think you mentioned on was it Sam Harris that the left these liberal journalists only follow each other in

the run up to the 25th 2016 elections. Yeah.

And so I mean, I, I still believe that to be true. I've worked in these offices, it

has changed. They've done the study, again, the visualization. And now there is a lot more cross pollination. But we what we saw is folks who are putting in the left end of the spectrum, mainly followed folks on the left, and folks on the right,

followed everyone, right, you were talking about earlier that there's bubbles,

there's there's bubbles, and we've helped create them and maintain them. So

here's what ends up happening. And this is one of the big problems that people have with this story. Particularly, particularly, you have a left wing activist who works for NBC News, I'm not accusing you of having read the article. He right he's he spends like a day lobbying to twitter saying, Guys, you have to do this, you have to make these changes. The next day, he writes a story saying that 4chan is organizing these, these these harassment campaigns and death threats. And while 4chan was doing threads about it, you can't accuse 4chan simply for talking about because Reddit was talking about it too, as was Twitter. So then the next day, he after he published his article, now he's getting threats. And then Twitter, he has a statement saying we will take action. And to make matters worse, when John Levine, a writer for the rap got a statement from one of your spokespeople saying, Yes, we are banning people for saying learn to code. A bunch of journalists came out and then lied. I had no idea why saying this is not true. This is fake news. Then a second statement was published by twitter saying it's part of a Harassment campaign. And so then the mainstream narrative becomes, oh, they're only banning people who are part of a Harassment campaign, but you literally see legitimate high profile individuals getting suspensions for joining in on a joke,

oh, they're there, for sure. Probably mistakes in there. I don't think that any of us are claiming that we got this 100%, right. And probably

our team having a lack of context and to actually what's happening as well. And we would fully admit, we probably were way too aggressive when we first saw this as well. So I made mistakes. I

hope this clarifies then you have situations like this where you can see, you know that this journalist, I'm not going to name him but he routinely has very like left wing, I don't want to use overtly esoteric words, but intersectional dogmatic points of view, right. So this is concerning. So like intersectional feminism is considered like a small ideology. It people refer to these groups as the regressive left or the Identitarian. Left. These are basically people who hold views that a person is judged based on the color of their skin, instead of the content of their character. So you have the right wing version, which is like the alt right, the left wing version, which is like intersectional feminism is how it's typically referred to so you'll see people say things like, you know, when they when typically when they rag on white men, or when they say like white feminism, these are these are signals that they hold these particular views. And these views are becoming more pervasive. So what ends up happening is you have a journalist who clearly holds these views. Don't you want to call him a journalist? He writes extremely biased and out of context story. Twitter takes action in response seemingly in response, then we can look what happens with Oliver Darcy at CNN. He says, you know, the people that see PAC are the Conservatives are gullible eating red meat from Grifters. Among other things, disparaging comments about the right. And he's the one who's primarily advocating for the removal of certain individuals who you then remove. And then when Kathy Griffin calls for Daxing, that's fine. When this guy calls for the death of these kids, he gets he gets a slap on the wrist. And look, I understand the context matters. But grains of sand to make a heap and eventually you have all of these stories piling up. And people are asking you why it only flows in one direction cuz I gotta be honest, I'd imagine that calling for the death three times of any individuals a bannable offense, even without a warning, just get rid of them. But that didn't happen. Right? We see these you know, people say men aren't women though and they get a suspension. We see people say the editor in chief of The Daily Caller, maybe the best example, hashtag learn to code, quoting the daily show and he gets us Pension threatening death and inciting death is a suspension to it feels like it's only going in one direction.

I think we have a lot of work to do to explain more clearly when we're taking action and why. And certainly looking into any mistakes we may have made in this particular situation. So

would you guys agree that in tech, I think we can all agree this, I would hope you agree. Tech tends to lean left. Like tech companies, Facebook, Twitter, Google,

I would be willing to bet that a conservative running a social network would not have a hate speech policy. I mean, you look at gab and you look at minds and minds, not even right wing,

right. They're not right wing at all. They're just they just staunchly support free speech. I don't think gab is necessarily I don't think the owner is necessarily right wing either.

I don't know much about him. I think he's like a libertarian. I don't want to

I don't want to specify either. I don't I don't know enough. yet. I know that there. When you read what they write. They're just staunchly committed to free speech. But they no stop Daxing they will they will do things to stop targeted harassment and Daxing. and things along those lines. Sometimes slowly. Yeah, heatedly. Yeah. But they want, they just want an open platform. What my point is, is that I think a lot of people that are on the right, feel disenfranchised by these platforms they use on a daily basis. I don't know what the percentage are. The percentages are in terms of the number of people that are conservative that use twitter versus the number of people that are liberal. But I would imagine it's probably pretty close, isn't it?

I don't know numbers? I don't know. Because we don't ask people. But we'd

have to we'd have to infer all that based on what we're saying or because so let's not

even go there. But then but the the people that run, whether it's Google or Twitter, or Facebook, any of these platforms, YouTube, for sure. Powerful leaning towards the left. When we all agree to that,

we don't ask our employees. But my guess is that many employees and tech companies are probably liberal.

It's really fascinating. But

I also think I mean, you point out, all the companies you mentioned are in exactly the same region, as well. Yes. We do. You know, we do have the challenge of some monocultural thinking, Yes, well, but we and we, you know, I have said publicly that, you know, yes, we will have more of a liberal bias within our company. So there's to CNN, right. But that doesn't mean that we put that in our rules, right? But

hold on. Because what I'm getting at is that at some point in time, things have to get down to a human being, looking and reviewing cases. And if you guys are so left weighing in your, your, your staff and the area that you live in, and all these things, things are almost naturally going to lean left. Is that fair to say? If

we were purely looking at the content, but a lot of this agent work is based on the behaviors, all the things that we've been discussing in terms of the context of the actual content itself, except it doesn't what the rules are,

except the misgendering policy, right? So your rules do reflect your your bubble, right, go to the middle of you know, go to middle America and go hang out at a conservative town, they're not going to agree with you. Your rules are based on your bubble in San Francisco, or whatever city I'm

from Middle America. I'm from St. Louis, Missouri. And I hear the point, I definitely hear the point in terms of like us putting this rule forth. But we have to balance it with the fact that people are being driven away from our platform. I hear you and they may not disagree. They may not agree with me on that my folks from Missouri, but I think they would see some valid argument and what we're trying to do to again, increase the opportunity for as many people as possible to talk. That's, that's it, it's not driving the stuff that you're speaking to

where you stop, what what community is and isn't deserving of protection? are conservatives not deserving of protection for their opinions. But

I want to focus in a way on individuals and increasing the absolute number of people who have opportunity to speak on the platform in the first place.

So then do you need a rule for body dysphoria? Do you need a rule for other kin? Right, you see what I'm asking you? You have a specific I

see what you're asking. But like and this came from a call and research. And there's there's disagreement as to whether this is the right outcome or not. And this is the right policy. And yes, our bias does influence looking in this direction. And our bias does take our biases influence us putting a rule like this in place, but is with the understanding of creating as much opportunity as possible for as many people to speak based on the actual data that we see right of people leaving the platform because of experiences that have Why did your research stop there? It hasn't stopped. We our rules aren't set. It's something that just stops and doesn't evolve. We're going to constantly question we're going to constantly get feedback from people on every Under the spectrum of any particular issue, and make changes accordingly and

to your stop. And to your credit, I really do appreciate that the fact that you're very open about that you have made mistakes, and that you're continuing to learn and grow and that your company is reviewing these things, and trying to figure out which way to go. And I think we all need to pay attention to the fact that this is a completely new road, this road did not exist 15 years ago, there was nothing there. That is a tremendous responsibility for any kind of any company, any group of human beings to be in control of public discourse on a scale unprecedented in human history. And that's what we're dealing with here. This is not a small thing. And I know people that have been banned to them. This is, this is a matter of ideology, this is matter. This is matter that there's a lot of debate being going on here. And this is one of the reasons why I wanted to bring you on because Tim, because you know so much about so many of these cases and so much because you are a journalist, and you're you're very aware of the implications and all the problems that have been that maybe have slipped through my fingers. So I

do want to make one thing really clear, though, I have a tremendous amount of respect and trust for you. And you said you wanted to solve this problem simply because you're sitting here right now. And these these other companies aren't right Jackie went on Sam Harris, you are on get with gad sad. And that says to me a good faith effort to try and figure out how to do things right, like so as much as I'll apologize for getting kind of angry and being emotional because he

was angry. I look, we also haven't been great at explaining our intent. And there's there's a few things going on one, as Joe indicated, centralized global policy as scale is almost impossible. And we realize this different services have different answers this Reddit has a community based policy where each topic each subreddit has its own policy. And you know, there's there's some benefit to that. So that's problem number one, we know that this very binary off or on platform isn't right. And it doesn't scale. And it ultimately goes against our key initiative of wanting to promote more healthier conversation. I,

I just don't think that's what you're doing.

I and I hear you, I hear you, but like, so but we're not done. We're not We're not done, we're not finished with our work. And we need to the reason I'm going on all these podcasts and having these conversations and ideally, videos getting out there more often as well, because we don't see enough friend here enough for her. We need to have these conversations so we can learn we can we can get the feedback and also pay attention to where the technology is going before the podcast we talked a little bit about and I talked about it on our previous podcast and also Sam's that technology today is enabling content to live forever in a way that was not possible before. You can say that everything on the internet lives forever. But that's not it's generally not true. Because any host or any kind of connection can take it down, the blockchain changes all that it can actually exist forever, permanently, without anyone being able to touch a government company, individual. And that is a reality that we need to pay attention to. And really understand our value. And I believe a lot of our value in in the future. Not today, again, we have a tons of we have a ton of work is to take a strong stance of like, we are going to be a company that given this entire corpus of conversation and content within the world, we're going to work to promote healthy public conversation. That's what we want. That's what we want to do. And if you disagree with it, you should be able to turn it off. And you should be able to access anything that you want as you would with the Internet. But those are technologies that are just in the formative stages and presenting new opportunities to companies like ours, and and there's a ton of challenges with them and a ton of the things that we've discussed over the past hour that it doesn't solve and maybe exacerbates, especially around things like election interference, interference and some of the regulatory concerns that you're bringing. So

there's a few issues right, your definition of what isn't healthy, right? Yes,

yes. And we want that to be public. Like we want that we're going we have four indicators right now that we're working on with an external lab, we want other labs to we want to give it up open source, make sure that people can comment on it. If people can help us define it. We'll use that interpretation on our own algorithms and then push it but that has to be open that has to be transparent. Are we there today? Absolutely not. We're not there.

i This this course of action to me looks like a Fahrenheit 451 future where everything is so offensive, everything must be restricted. I see. That's the path I see that you're on. You want to have a healthy conversation you want to maximize the amount of people that means you got to cut off all the tall grass and level everything out. So if you decided that this one rule needs to be enforced, because certain things are offensive, but

can I explain what what health at least means to us in this absolutely. Yeah. So like we talked a little bit about this on the previous podcast, but like we we have four indicators that we're trying to define and try to understand if there's actually something there one is shared attention. Is a conversation generally shared around the same objects, or is it disparate? So, like, as we're having conversation, the four of us are having conversation? Are we all focused on the same thing? Or is Joe on his phone, which you were earlier, like whatever is going on, because more shared attention will, will lead to healthier conversation. Number two, is shared reality, not whether something is factual. But are we sharing the same facts? Is the earth round? Is the world flat? So we recommend when our met Yes, we can tell what facts are we sharing? And what facts are we not sharing what percentage of the conversation so that's, that's the second indicator. Third is receptivity. Are the participants receptive to debate and to civility and to expressing their opinion and even if it is something that might be hurtful, or people receptive to at least look at and be empathetic and look at what's behind that week? This is the one we have the most measurement around today, we can determine and predict when someone might walk away from a Twitter conversation because I feel it's toxic. I just ignore them all, basically. So and we see we see that in our data, right? So you and there's some conversations that you get into and you and you, you know, persist. And then the finally is for it of perspective, are we are we actually seeing the full spectrum of any topic that's been talked about. And these are not meant to be taken as individual parts, but in unison, how they play together. And we've written these out, we haven't gotten far enough in actually defining what they look like and what they mean. And we certainly haven't gotten good enough at understanding when we deploy a solution, like being able to follow a hashtag. Does that impact variety of perspective to the positive? Does it impact shared reality to the negative whatnot. So this is how we're thinking about it. And as we think more about that, that influences our product and influences. Our enforcement and influencers are positive as well, what you're

describing sounds wildly different to what Twitter is, right? So you have a goal for where you want to get with those, those metrics. So what confuses me, then when you when we talk about someone like Megan Murphy, who sure she violated your rules, but in the context of a conversation, you know, you recognize people will sometimes get heated with each other? If, you know, how do you is a healthy conversation when no one is being negative? What if people are yelling at each other and being mean and insulting or misgendering? them?

I think it's a question of what thresholds you allow. And the more control we can give people to vary the spectrum on what they want to see. That feels right to me. I mean, Joe, in in your your Alex podcast, did exactly this thing. you're hosting a conversation, you had both of your guests who started talking over each other, you pause the conversation, you said, Let's not get combative, someone said, I'm not being combative, you said you're all talking over each other. And and there was a dynamic that the conversation then shifted to that got to some deeper points, right? could have just said, let that happen and let it go. And that's fine, too. It's, it's, it's up to who is viewing and experiencing that conversation. And I agree with you. It is completely far off from where we are today, we've not only have, we had to address a lot of these issues that we're talking about at this table. But we've also had to turn the company around from a business standpoint we'd have we've had to fix all of our infrastructure that's over 10 years old. And we had to go through two layoffs because the company was too large. So we have to prioritize our efforts. And I don't know any other way to do this than be really specific about our intentions and our aspirations and, and the intent and the why behind our actions. And not everyone's going to agree with it in the in a particular moment.

So so I will I want to I want to point this out. Before I make my next statement, though, just real quick, it seems like the technology is moving faster than the culture. So I do recognize you guys are in a rock and a hard place. How do you get to a point where you can have that open source crypto, you know, blockchain technology that allows for freedom and speech. At the same time, the technology exists. Twitter has been replicated numerous times in different ways Macedon, for instance, what what's disconcerting to me is, you know, and maybe you have research on this, which is why you've taken the decisions you have, but when you banned someone, because they've said, you know, bad opinions misgendering well, they're not going to go away. They're going to try and find anywhere they can speak. So what effectively happens is you're taking all of these people from from a wide range of the most TOS of prison analogy, murderers all the way to pot smokers and you put them in the same room with each other and you're saying you're not welcome here. Well, what happens when you take someone who smokes pot and put them in prison with a bunch of gangbangers and murderers, they fall into that.

So I totally get the point. I'm hyper aware of of our actions sending more and more things into the dark. This

is something that I wanted to discuss this is really important in this vein of thinking, What about roads to redemption? What about someone like MEGAN MURPHY lit about someone, anyone? Alex Jones, Milo is is it? Can we find a path for people to get back to the platform? That for good or for bad? Like it or not, there is one video platform that people give a shit about. And that's YouTube, you get kicked off a YouTube, you're doomed. I mean, that's just reality, you can go. Vimeo is wonderful. There's a lot of great video platforms out there, they have a fucking tiny fraction of the views that YouTube does. That's just reality, the same thing can be said for Twitter, whether or not other platforms exist is that's inconsequential. The vast majority of people are on Twitter, the vast majority of people that are making you know, posts about the news and breaking information, they do it on Twitter. What can be set up? And have you guys given consideration to some sort of a path to redemption?

Yeah, there's, there's redemption and there's rehabilitation? Okay, you know, we we haven't done a great job at having a cohesive stance on rehabilitation and redemption, we haven't in part, so the whole focus behind the temporary suspensions is to at least give people pause and think about why they violated or why and how they violated our particular rules that they signed up for when they came in through our terms of service, right? Whether you agree with him or not, like, this is the agreement that we have with people,

you know, I'm just thinking this, I'm sorry to interrupt you. But it would be kind of hilarious if you guys had an option, like a mode of Twitter an angry mode, like fuck, I'm angry right now. So I'm going to type some things and it says, Hey, dude, why don't you just think about this? We're gonna hold it for you in the queue. And we'll

do that people do that. People do that in their drafts. But and I'm sure you

do. I'm sure they do. But it would be funny if you had an angry mode. Yeah, but you guys, I noticed you guys are using a lot of curse words. And he's saying a lot of bad things, we're gonna put you in Angry mode. So think about this. So you have to make several clicks, if you want to post this.

And there is research to suggest that people expressing that actually tends to minimize more violent physical. Oh, for

sure. Well, everyone says that with emails, if you're, if you're, if you're in the middle of the night, someone sends you an email and you find it insulting you ready to type an email and go to sleep? Wake up in the morning? Like, someone say something nice. You know, that's how I wind up interacting with these people. But what what do you think can be done for people like, let's say, MEGAN MURPHY, because she seems one of the it's as easy to see her perspective as any, what do you think could be done for her?

I think I think you're right, I think that I would love to get to a point where we think of suspensions as temporary, and she's banned for life. Right now. That's the only option that we've built into our rules. But we have every capability of changing that. And that's something that I want my team to focus on is thinking about, as Jack said, not just coming back after some time bound period, but also like, what more can and should we be doing within the product itself early on to educate people about the rules. So one of the things that we're working on is a very, very simplified version of the Twitter rules. That's two pages, not 20. I've made sure that my lawyers don't write it. It's written in as plain English as we can we try to put examples in there. And like really taking the time to educate people. And I get people aren't always going to agree with those rules. And we have to address that too. But at least simplifying it and educating people so that they don't even get to that stage. But once they do, understanding that there are going to be different contexts in people's lives, different times, they're going to say and do things they may not agree with. And they don't deserve to be permanently suspended for ever, from a platform like Twitter. So how do you get to it? So we this is something that actually we just had a meeting on this earlier this week, with our executive team. And, you know, identifying kind of some of the principles by which we would want to think about, you know, time bounding suspension. So it's work, we have to do it, and we're gonna figure it out. I'm not going to tell you it's coming out right away. But it's, it's on our roadmap. It's something we want to do.

Why don't you set up a jury system? When someone reports something instead of you having to worry about it? There would be no accusation of bias if 100,000 users were randomly selected to determine Periscope does this Yeah. Yeah.

And we've learned scope does this you please explain that

we so Periscope has a content moderation jury. So we flag based on the machine learning algorithms, in some cases reports, particular replies, we send them to a small jury of folks to ask, is this against our terms of service or is this something that you believe should be in the channel or not?

Do you know sign out? To be on the jury.

No, it's It's random.

So you randomly chosen and you decide whether or not you want to participate. Yep.

And it's, it's good. It has some flaws. It has some some gaming aspects to it as well. But like, we do have a lot of experiments that we're testing and like, we want to build confidence and like it's actually driving the outcomes that we think are, are useful. And Periscope is a good playground for us across many regards. I think ultimately,

one of the greater philosophical challenges is that you're a massively powerful Corporation. You have international investors, I believe, as a Saudi prince owns what 6% of Twitter. So when I Is that true, I'm just gonna make sure it's, well, we're we're a publicly

traded corporate Alright, so anybody can buy stock, but that doesn't mean they have influence on day to day. Well, I

think depending on which political faction you ask, they'll say money is influence, right. So I'm not gonna say that the Saudi prince who invested in Twitter, because again, I've only it's been a while since I've read these stories is like showing up your meetings and throwing his weight around. But at a certain point, I plan on doing that. But but you know, for me, I do have to trust you, right. This is a guy who is thrown thrown in over a billion dollars, I think, into Twitter. Twitter has influence on our elections, foreign governments, foreign government actors have stake in Twitter, it worries me then when you base your rules on your personal decisions on an unelected group of people. You have such tremendous power in this monopoly on public discourse near monopoly. Like he was saying, there's some platforms, Twitter has no real competition. So I just have to hope and trust you have the best interest at heart. But you at the end of the day, it's it's it's authoritarian. No one chose you to be in charge of this. I understand you mentioned you discovered Twitter. But here I am looking at you know, both of you who have this tremendous power over whether or not someone can get elected, you can choose to ban someone and tell me all day and that you have a reason for doing it. I just have to trust you. That's terrifying. There's no proof. There's no proof Alex Jones did any of these things other than things he's posted? Right? Understand that

that's actually what I was on the phone with. Alex was texting me saying that he'd never did anything to endanger any child, and that he was disputing what people were saying about a video of a child getting harmed. And

so do we just trust an unelected? I mean, you extreme extremely wealthy individuals, Saudi princes. You know, it's a publicly traded company, who knows where the influence is coming from. Your rules are blatant based on a global policy. And I'm sitting here watching Wow, these people who are never chosen in this position have too much power over my my politics.

I think that that's why it's so important that we take the time to build transparency into what we're doing. And that's part of what we're trying to do is not just in being here and talking to you guys, but also building it into the product itself. I think one of the things that I've really loved about a new product launch, what we've done is to disable any sort of ranking in the home timeline if you want, and you don't have to see our algorithms at play anymore. These are the kinds of things that we're thinking about, how do we give power back to the people using our service, so that they can see what they want to see. And they can participate the way they want to participate? And this is long term, and I get the we're not there yet. But this is how we're thinking about it, then

you can imagine where that goes, I mean, just one switch, and turning all the algorithms off. What what does that do? What does that look like? So these are the conversations that we're having in the company, whether they be good ideas or bad ideas? We haven't determined that just yet. But we we definitely. Look, I definitely understand the mistrust that people have in our company in myself in the corporate structure in all the variables that are associated with it, including who chooses to buy on the public market, who chooses not to, I get all of it. And I grew up on the internet. I'm a believer in the internet principles. And I want to do everything in my power to make sure that we are consistent with those ideals. At the same time, I want to make sure that every single person and do everything in my power has the opportunity to participate. So let me

let me ask you a question that for your policy, as it pertains to say Saudi Arabia, right, do you enforce the same hate speech rules on Saudi Arabia?

Our rules are global, we enforce them against everyone. So

even in countries where it's criminal to be LGBT, you will still banned someone for saying something disparaging to or saying something that to that effect. Like, let's say Saudi Arabia said someone's put to death for I don't want to call it Saudi Arabia specific. Let's call it Iran, because I believe that's the big focus right now with the Trump administration. Iran is my understanding, it's still punishable by death. I could be wrong. But it is criminal. If someone then directly targets one of these individuals, will you ban them? I mean, do you guys function in Iran? Because I think we're blocked in Iran. Yeah. So I figured but there but there are some countries where, for instance, Michelle Malkin recently got really angry, because she received notice that she violated blasphemy laws in Pakistan. Right. So you do follow some laws in some countries, but it's not a violation. I guess the question I'm asking is we Pakistan, it's very clearly a different culture. They don't agree with your rules. We do have

a per country ticked down, meaning that content might be non visible within that country but visible throughout the rest of the world.

But so just to add on to what Jackson we actually are very, very transparent about this. So we put publish a transparency report every six months that details every single request that we get from every government around the world, and the content that they ask us to remove. And we post that to an independent third party site. So you could go right now and look and see every single request that comes from the Pakistani government and what content they're trying to remove from Pakistan. I

have seen a lot of conservatives get angry about this. And it's kind of confusing, confusing, I'm like, that's a really good thing. I would want to know if Pakistan wanted to kill me. blasphemy laws posting pictures of Muhammad. So it's

like, Are they angry about our transparency report there, there's

a perception that you sending that notice is like a threat against them for violating blasphemy laws. Whereas it's very clearly just letting you know, a government has taken action against you, which

it's saying that the government has restricted access to that content in that country. And the reason we tell users or tell people that that's happened is because a lot of them may want to file their own suit against the government, or a lot of them may be in danger if they happen to be under that particular government's jurisdiction. And they may want to take action to protect themselves if they know that the government is looking at the content in their accounts. So we don't always know we don't we send the notice to everybody, we don't always know where you are or what country you live in. And so we just done that notice as like to try to be as transparent as possible. The

main point I was trying to get to is your policies support a community, but there may be laws in a certain country that does not support that community finds it criminal, right. So your actions are now directly opposed to the culture of another of their country. I guess the point I'm trying to make is that if you enforce your values, which are perceivably, not even the majority of this country, if you're, you know, consider yourself more liberal leaning in your half of the United States, but you're enforcing those rules on the rest of the world that use the service, it's sort of forcing other cultures to adhere to yours.

So a lot of a lot of our rules are based on more the UN Declaration doesn't just purely us,

doesn't the UN Declaration guarantee the right of all people through any medium to express their opinion. It

does. And it also has can, it also has conditions around particular speech, inciting violence, and some of the some of the aspects that we speak to as well. And

it protects certain categories, whether it's religion, race, gender, sexual orientation, those are all also protected under the UN covenant, to protect human rights.

without pause. I'm sure we have many more things to talk about, don't worry, I don't want to just just say, I've

got a bunch of other things that you know, because here's the here's the thing, there's a bunch of other issues having to do with bias and censorship. And I feel like we've kind of like beaten that horse relentlessly.

But I think that horse is good to beat. And it's also good to address why the horse is being beaten and why why it exists in the first place. And I, I really want to say this, again, I really appreciate the fact that you guys are so open, and that you're willing to come on here and talk about this because you don't have to, this is your decision, and especially you Jack after we had that first conversation, and the blowback was so hard, you wanted to come and clarify this. And I think this is so important to give people a true understanding of what your intentions are versus what perceptions are.

And thank you for hosting us again. And look, I I think it's also important that the company is not just me, we have people in the company who are really good at this and are making some really tough decisions and having tough conversations and, and getting pushed back and getting feedback and they have the best intentions. So

what So let's, I'll get back into the meat of things to get to beating the dead horse. I don't know if you have any data on why Jacob wall was recently banned. Do you have that?

I believe who was Jacob wall.

He's a I don't know, describe me as a conservative personality. But he's very, very controversial for like, fake news or something. I don't know too much about him. So I don't want to accuse him of things, but I don't know who he is. But he was, he was in something where he tried accusing Mueller of like sexual assaults. And it turned out to be like, just completely fake ridiculous.

This was a gentleman that was in the USA Today article where he admitted that he was going to he had used tactics in the past to influence the election, and he will continue to do so using all of his channels. Yes.

And when we saw that report, our team looked at his account, we noticed there were multiple accounts tied to his account, so fake accounts that he had created that were discussing political issues and pretending to be other people find that out. We would have phone numbers linking accounts together or email addresses, in some cases, IP addresses other types of metadata that are associated with accounts so we can link those accounts together. And having multiple accounts in and of itself is not a violation of our rules. Because some people have their you know, word account their personal account is when you're deliberately pretending to be someone else and manipulating it. servation about a political issue. And those are exactly the types of things that we saw the Russians do, for example, in the 2016 election, so it was that playbook and that type of activity that we saw about Jacob wall, and that's why his accounts were suspended.

Did you investigate Jonathan Morgan?

I don't know who that is. Why?

That's that's the important question. Why

I don't I don't know who that is. But that's that's ice. It might be that someone at Twitter investigated him. I personally don't know who so

one of the issues that I think is really important to get to is, you should know who he is. He's more important than Jacob Wallace. But for some reason, you know, about this conservative guy and not the Democrat who helped meddle in the the Alabama election. Well, so Jonathan, according to

the near sheer volume they have to pay attention to right, right, right. But

it's about grains of sand, making the heap and the flow of a direction where we can see Jacob wall has said he's done this. So you're like, we're gonna investigate, we banned him. It was recently reported and covered by numerous outlets that a group called new knowledge was meddling in the Alabama election by creating fake Russian accounts, to manipulate national media into believing that Roy Moore was propped up by the Russians. Facebook banned him and as well as for other people, but Twitter didn't.

He's still active family accounts that were engaged in the behavior.

I do remember that. I do remember sending Mr. Martin. That's worse, though.

So you didn't ban the guy doing it. But you banned the like so.

So in the case of Jacob wall, we were able to directly attribute through email addresses and phone numbers, his direct connection to the accounts that were created to manipulate the election. If we're not able to tie that direct connection on our platform, or law enforcement doesn't give us information to tie attribution. We won't take action. And it's not because of political ideology, it's because we want to be damn sure before we take action on it. So someone

could use a VPN, perhaps, and maybe additional email accounts. And they could game the system in that way.

They're certainly sophisticated ways that people can can do things to mask who they are, and what accounts that they're

interested in internal conversation to, just to provide more light into what happens, like I got a I got a email or a text from vigia one morning and said, we are going to permanently suspend this particular account. And it's not a you know, what do you think it's, we're going to do this, and I then have an opportunity to ask questions, I asked a question why she gave me a link back to the document of all the findings. And USA Today. We took the action. I was on Twitter, a bunch of people pointed me at this particular case sent some of those tweets to her, what's going on? So that's well, in the background?

Wouldn't you just terminate anybody associated with the company that was doing this? I mean, keep in mind, too, at the time when this campaign was happening, this is what basis he had he admitted to engaging in the operation in a quote to New York Times, and you banned the accounts associated with it. So if you know he's the one running the company, wouldn't you be like, Okay, you're gone?

Do you want us to take every single newspaper accounts, attribution, because what we were able to do in the Jacob ball situation was actually tie those accounts in our own systems. Right, that he would actually control the rounds, not just take the word of a newspaper. You said

you banned his accounts? Yes. And you know, from his own statement, and from his tweets that he was the runner running, running the company, Jacob wall, no, no, Jonathan Morgan.

Oh, sorry. I'm getting confused about over. So

Jacob wall, it's announced in the USA Today. He says I'm doing this and you're like, Okay, we can look at his account, we can see it, we get rid of them. With with new knowledge, you said you did take those accounts down, I

believe we were able to take down a certain cluster of accounts that we saw engaging in the behavior, but we weren't weren't necessarily able to tie it back to one person controlling those, even if they say they did it, do you and this is where I get back. Like we like to have some sort of attribution that's direct that we can see. Would we just take the any newspaper or any article at face value and just act on them?

That's good. You have to contact him and get some sort of a statement from him in order to take down his account. Obviously,

I don't think he would admit to manipulating Twitter if Twitter asked him. So

the fact that he communicated with the newspaper right,

so to clarify, what they said what they claimed to the New York Times was that it was a false flag. New York Times said they reviewed internal documents that showed they admitted it was a false flag operation. The guy who runs the company said, Oh, his company does this. He wasn't aware, necessarily. But it was an experiment. So he's, he's given kind of, in my opinion, duplicitous, like, you know, not straightforward, but at the time of this campaign, which he claims to know about, he tweeted that it was real. So during the Roy Moore campaign, he tweets Wow, look at the Russians. Then it comes out later. His company is the one that did it. So you're kind of like Oh, so this guy was propping up his own fake news. Right. Then when they get busted? He goes, Oh, no, it's just my company doing an experiment but you tweeted it was real pyramid. You use your verified Twitter account to push the fake narrative your company was pumping on this platform. And so the point I want to make I guess, is

it sounds like we need to take a closer look at this one ban and

bring back Morgan morale. Well, MEGAN MURPHY, MEGAN MURPHY. Sorry. Morgan Murphy is a friend of mine. To

sorry, Morgan. So this is I haven't read the story. It's been like two months since the story broke. So I could have my you know, I don't want to I don't want to get sued and have my facts wrong. But the reason I brought this up was not to accuse you of wrongdoing was to point out that I don't I don't think that the people who work at Twitter are twirling their mustaches, laughing, you know, pressing the band button, whenever they see a conservative, I think it's just, there's a bias that's unintentional, that flows in one direction. So you see the news about Jacob wall. And I think there's a reason for it, too, there's a couple of reasons. For one, your your staff is likely more, you mentioned, more likely to lean left, and look at certain sources. So you're gonna hear about more things more often, and take action on those things, as opposed to the other side of the coin.

But we have to consider like where the actions are taking place. I'm speaking more broadly to the 4000 people that we have as a company versus no deliberateness that we have unreduced him for,

I just mean when we when we look at a company wide average of all of your employees and the direction they lean, versus the new sources they're willing to read, you're going to see a flow in one direction, whether it's intentional or not. And so I think the challenge is, we

don't generally rely on news sources to find manipulation of our platform, but we're looking at what we're seeing the signals we can see. And once in a while, we will get tipped off to something but like, for the most part, when we're looking at manipulation, it's not like the New York Times can tell us like what's going on on the platform. We're the ones that have the metadata about accounts, we're the ones that can see patterns of behavior at scale. So

to your point, I knew one name, and I didn't know another name. And it was because video said, you know, we're permanently banning this account. And yes, we we didn't have the same sort of findings in the other particular account, which I got feedback on pass to her. And we don't need to find, I think,

but to be clear, the team had taken action on this stuff months ago, when it actually it happened. Yeah, I

think, you know, a lot of what people assume is mal intent is sometimes fake news. You know, I think one of my biggest criticisms, in terms of what's going on our culture is the news system is, like you pointed out, although it's changed, left wing journalists only follow themselves, I that's my experience, I've worked for these companies. And so they repeat the same narratives. They don't get out of their bubble, even today, they're still in a bubble. And they're not seeing what's happening outside of it. And then what happens is, you know, according to data, I think this is from Pew. Most new journalism jobs are in blue districts. So you've got people who only hear the same thing, they only cover the same stories. So if you know, we hear about Jussie Smollett, we hear about how the story is it goes goes wild. But there's like 800 instances of Trump supporters wearing Magga hats getting beaten. You know, throughout the past couple of years, we had a guy show up to a school in Eugene, Oregon with a gun and fire two rounds at a cop wearing a smash the patriarchy and chill shirt. And those stories don't make the headlines. So it's, you know, when the journalists are inherently in a bubble, the information you're going to get as a big company who follows these news organizations is going to be inherently, you know, one sided as well. And then the only action you're gonna be able to take is what you know, you can't ban someone if you don't know they're doing it.

Here. I think our biggest issue, and the thing that I want to fix the most is the fact that we create and sustain and maintain these echo chambers.

Yeah. Well, you're rolling out that new feature that allows you to hide replies, right?

We're testing we're experimenting with an ability to enable people to have more control, as you would expect a host over the conversation. And like Facebook allows that, yeah, but I don't think they have the level of transparency that we want to put into it. So we actually want to show whether a comment was moderated and then actually allow people to see those comments. So both showing the action that this person moderated a particular comment. And then you can actually see the common itself. It's one, one, click one, click over one tap over. That's how we're thinking about it might change in the future. But we, we can't do this without a level of transparency, because we minimize something visited spoke to earlier, we're just speaking truth to power holding people to account. Even things like the fire Festival, where, you know, you have these organizers who were deleting every single comment moderating every single comment that call this thing a fraud, and don't go here. We can't, we can't, we can't reliably and we like just from a responsibility standpoint, ever create a future that enables more of that to happen. And that's how we're thinking about even futures like this,

I'm gonna jump right off to a different train card here. Has law enforcement ever asked you to keep certain people on the platform even after they violated your rules?

Not that I'm aware.

So then this you know, to the to the next question pertaining to bias, you have the issue of Antifa versus the proud boys and Patriot prayer and Twitter permanently excised anyone associated with a proud boys Antifa accounts who have broken the rules, repeatedly branded known cells that have been involved in violence all still active.

Is there a reason? Well, with the proud boys, what we were able to do was actually look at documentation and announcements that, you know, the leaders of that organization had made and their use of violence and The real world. That was what we're focused on and subsequent to our decision, I believe the FBI also designated that's not true. It's not true. That's not true.

No. Okay. No, that's not true. Yeah. You know, the proud boys started out as a joke. Gavin McInnes, Anthony KU, Mia, who was part of Opie and Anthony knows his own show, told me about it, it happened on his show, because there was a guy that was on the show. And they made a joke about starting a gang based on him because he was very effeminate guy, and they would call him the proud boys. And they went into detail about how this thing became from a joke. And saying that you could join the proud boys and everyone was, you know, it was like being silly to people joining it, and then it becoming this thing to fight Antifa and then becoming infested with white nationalists, and becoming well thing. Well, in many ways, it was, but it's been documented how it started and what it was and misrepresented as to why it was started.

I think there's some things that should be clarified about them. But Gavin has made a bunch of statements that crossed the line, he claims he claims to be joking. And so that's, that's what he

did on my podcast, he was talking to me about Antifa, that when Antifa was blocking people like Ben Shapiro speeches and things along those lines and stopping conservatives for speaking, you should just just punch him in the face, we're gonna have to start kicking people's asses. And I was like, this is not just irresponsible, but foolish and short sighted and just a dumb way to talk. So

then you have the Antifa groups that are engaging in the same thing. We know that the famous bike lock basher incident where a guy showed up, hit seven, he hit seven people over there with a bike lock. They subsequently released the damn, I'm gonna leave that out for the time being. You have other groups like by no means and by any means necessary. You have in Portland, for instance, there are specific branded factions. There's the tweet I mentioned earlier, where they doxed ICE agents, and they said, Do whatever inspires you with this information? And I mean, you're tagged in a million times. I know you probably can't see it. But you can actually see that some of the tweets in the threat are removed. But the main tweet itself from an Anti Fascist account linking to a website, straight up saying like, here's the private home details, phone number addresses of these law enforcement officers is not removed since September. So here's what you end up seeing is. Again, the point I think one of the big problems in this country is the media, because it was reported that the FBI designated probe was an extremist group. But it was a misinterpretation based a sheriff wrote a draft saying with you know, the FBI considers them to be extremists. The media then reported hearsay from the sheriff and the FBI came out said no, no, no, we never meant to do that. That's not true. We are just concerned about violence. So the proud boys all get purged. And again, I think, you know, Gavin's a different story, right? If you want to go after the individuals who are associated with that group, versus the guy who goes on the show and says outrageous things and goes on Joe's show. And then you have Antifa branded cells, like what I mean by that is they have specific names, they sell merchandise, and they're the ones showing up throwing mortar shells into crowds. They're the ones showing up with with crowbars and bats and whacking people. I was in Boston, and there was a rally where conservatives were planning on putting on a rally It was literally just like libertarians and conservatives. Antifa shows up with crowbars, bats in balaclavas with weapons, threatening them. And so I have to wonder if if, you know, these people are allowed to organize in your platform? Are you concerned about that? Why aren't they being banned when they violate the rules?

Yeah, absolutely. We're concerned about that has the FBI designated them as a domestic terrorist?

I'm sorry, Homeland Security in New Jersey has listed them under domestic terrorism. Okay. So I understand is a conundrum in that the general concept of anti Fascism is a loose term, that means you oppose fascism. But Antifa is now they have a flag. They've had a flag since the Soviet, you know, Nazi Germany in the Soviet era. And they've brought it back. There are specific groups that I'm not going to mention by name that have specific names, and they sell merchandise, they've appeared in various news outlets, they've expressed their desire to use violence to suppress speech. There was a

is it a centralized organization the same way that I hear you on Prometheus, but like, where they have, like tenants that are written out and there's a leader and like, not

it's not the same, but there are specific branded cells and that's why I bring them up specifically, I realize, you know, someone showing up to a rally wearing a black hoodie and sunglasses, we're gonna ban, but there are groups that that organize, specifically call for violence. They push the line as close as as lightly as possible. They advocate sabotage and things like this. And you know, when the proud boys go on, get into fights, they're not getting in fights with themselves. They're, you know, so I should

point out the they decided to call for violence based on an Tifa calling for violence. Yeah, based on an Tifa actually actively committing violence against conservative people that were there to see different peoples. Well, it

partly started because in Berkeley, there was a Trump rally. So actually, after Milo got chased out of the Berkeley, they there was $100,000 in damages. I mean, there's a video of some guy and all black cracking someone on the back was on the ground looking like they're unconscious. So these conservatives see this, and they decide to hold a rally saying we won't back down. They hold a rally in Berkeley and then anti shows up again, I understand you can't figure out who these people are, for the most part, they're decentralized. But then this incites an escalation, you then get the rise of the base to stickman. They called it this guy shows up in armor with a stick and starts swinging back. And now you have two factions forming. So while I recognize it's much easier to ban a top down group, there are you know, the difference, I guess, is while when you look at the proud boys, it's straight top down vertical, you look at Antifa. And there's different cells of varying size, and they're different accounts. So I have to to, like I guess the argument I could make is, if you're going to bend the proud boys, by all means under your justification. But if you look at a specific channel that's got 20,000 followers that cheers them on, right? These are people who throw mortar shells into crowds. Isn't that advocating for, you know, terrorism and incitement of violence? Yeah, absolutely. So I guess the question is, how come they don't get removed?

Well, in the past, when we've looked at Antiva, we it's we ran into this decentralization issue, which is we weren't able to find the same type of information that we were able to find about Prometheus, which was a centralized leadership based documentation of what they stand for. But absolutely, I mean, it's something that we'll continue to look into. And to the extent that they're using Twitter to organize any sort of offline violence that's completely prohibited under our rules. And we would absolutely take action when I

asked you why Gavin was banned. Was there a specific thing that he did? Or was it his association with the proud boys association with the, you know, he's abandoned that he's not only that he's disassociated himself with it and said that it completely got out of hand, and he doesn't want to have anything to do with it.

Yeah. And I think this is a great, again, test case for how we think about getting people back on the platform. Yeah.

He's an interesting case, because he's a really a provocateur, and he fancies himself, you know, sort of a punk rocker. And he just, he likes stirring shit. I mean, when he came on my show, last time he was on, he was dressed up like Michael Douglas and falling down. You know, he did it on purpose. He brought a briefcase and everything. I'm like, What are you doing? It's like, I'm Michael Douglas, and falling down. Like, he's, he's a showman in many ways. And he did not mean for this to go the way it went. He thought it would be this sort of innocent fun thing to be a part of, and then other people got involved in and then when people call for violence. The problem is, they think that, you know, you're going to just hit people, and it's going to solve a problem, it just creates a much more much more comprehensive problem. It's

important to point out Gavin said has had meant like he said things way worse than Alex Jones ever did target whether you whether you want to say it's a joke or not. He said things like, you know, choke them, punch them directly. Yep. But But I guess was the primary reason for getting rid of them was what you thought that the FBI had designated them an extremist group? No, because we

did it many months in advance. Okay. Yeah,

I was just so we just it was just his association with the proud boys.

I don't recall. And I would have to go back and I don't want to mistake things. I don't recall whether those statements that you're referring to of Gavin's were on Twitter.

So they weren't. There's another you know, when it comes to the weaponization of rules against like, Gavin isn't creating a compilation of things he's ever said out of context, and then sending them around to get himself banned. Other people are doing that to him activists who don't like him. And it's effective. In fact, I would actually like to point out, there's one particular user who has repeatedly made fake videos attacking one of your other high profile conservatives, so much so that he had to file police reports harassment complaint, and it just doesn't stop. You know, so I guess I'll ask this that to disregard if someone repeatedly makes videos of you out of context, fake audio, accusing you of doing things you've never done? At what point is that bannable? Yeah,

again, if it's targeted harassment, and we can establish that it's just a really hard thing with OS determining whether something is fake or not? Well,

it's also when things are out of context, you still have video of the person saying that I agree that it's out of context, it's disingenuous, but it's still the person saying it, and you're making a compilation of some pre existing audio or video. So

I think in the instance of Gavin, like, one of the things he said was like a call to violence, but he was talking about, like it was in the context of talking about a dog and being scolded. Yeah. So he was like, hit him just hit them. And then it's like, it turns out, he's talking about dog like, something wrong when they take that in a snippet, and then it goes viral, and it starts flagging, and you got to ban this guy, you don't get I understand, like, you know, but I guess the issue is if people keep doing that to destroy someone's life, so I think there's a bigger discussion. I think both of you could probably shed some important light on to outside of Twitter. This weaponization of content from platforms is being used to get people banned from their banking accounts. You know, there get there. We can talk about Patreon for instance, and again, I'm not this this may just be something you could chime in on Patreon banned man named Carl Benjamin, also known as Sargon of Akkad. He's also banned from Twitter. And it was

was you know why he got banned from Twitter.

I can see

that's an interesting one.

I do have some some of the details here. Do you want me to read them please? Okay.

Looks like it's gonna be gross. It's

not stuff that I love saying. But I will say it

more JAXA shouldn't make.

He doesn't like cursing either. Let's see, I curse more than he does. So I guess I should say first strike. Fuck white people kill all men die sis GM, none of the above qualify as hate speech.

What was that?

I don't have the dates. I'm sorry.

But he's he's a white guy. I mean, obviously he's joking around there. White people

it also sounds like he's trying to make the point about rules and how you enforce them not actually. Which

is also exactly why you get kicked off Patreon. He was exactly Yeah,

well, I know he also posted a photo of interracial gay porn at some white nationalist to make them angry. Yes.

Yeah, he's funny. Why? He's funny is

I I can understand how posting that photo is an egregious violation of the rules whether whether or not he was trying to insult some people. That's a

very good point. And I wanted to bring that up. Is porn, a violation of the rules?

Porn generally no?

Good, really good for you? Why would what happens in my feed all the time, I follow a couple of naughty girls. And occasionally they post pictures of themselves engaging in intercourse. I'm like, yikes.

So then, what else were the other strikes for Sargon?

Let's see. There was the use of a Jewish slur.

How do you use it?

To a person you traitor Remainer white genocide supporting Islam a file Jewish slur lover. That should keep you going hashtag Hitler was right.

But these are general opinions. These are. These are targeted

at somebody that sounds like he's being like he's making a joke. I understand

in context. It sounds like the other one. Like in context, what he's saying particularly the fact that he's a white guy. That doesn't sound like a racial slur at all. I mean, he's saying fuck white people is white

and context. Again, these are tied together, right? I always knew that person was not to be trusted that fucking Jewish slur. Oh, so there's,

there's a bunch of very specific person targeting, trying to be very pro boxing out a specific Jewish person.

I don't know the race of this person.

I'm sorry. And this is not okay. But this is not this is not parody. This is not joking.

We didn't view it that way. I'm just not I'm not trying to like researching and all this. I'm just telling you what they were.

I knew he had done things that were like egregious violations of the rules, because, you know, plain simple, I didn't bring him up to, you know, go through and try and figure out a feat, but that it does sound like at least the first one was meant to be a chunk of Yeah.

So potentially, but there are a bunch of others, if you want to hear him more than sure that cheap roses again, targeted. This is how I know one day that I'll be throwing you from a helicopter, you're the same kind of malignant cancer, don't forget it. So there's just it's not one thing or two things or three things. It's just like a bunch of them.

Visions of grandeur. Imagine think you're gonna throw someone from a helicopter, he doesn't bring you in that helicopter,

but but admittedly, so. So he is on YouTube by the name of Sargon of Akkad. He's a big account. And I've criticized him for being overly mean in the past. And I think it's exactly he gets angry. But he is very different now. And I guess the reason I brought him up was not very different now. So well, a lot of the content he makes is much calmer. He's he's less likely to insult someone directly. He

makes probably recognizing that he's on his last straw. Oh, definitely. Especially kicked off with Twitter. He's on YouTube, he's probably gonna mind his p's and q's. Oh, but so

the reason I brought him up again, but we'll move on was that activists found a live stream from eight months ago, I totally forgot why I was bring this up, because we've moved so far away from where we were. But they they pulled us a clip from an hour and a half or whatever, into a two hour livestream on a small channel, they only had 2000 views, sent to Patreon. And then Patreon said, Yep, that's a violation and banned him outright without warning, which I've gotten to understand is different from what you guys do you do suspensions first. But I guess the reason I was bringing up was to talk about a few things. Why blocking isn't enough why muting isn't enough. And if you think that it's driving people off the platform, people post my tweets on Reddit, I blocked them, they use a dummy account, load up my tweet posted to Reddit and then spam me on Reddit. So, you know, blocking and even leaving Twitter would never do anything short of me shutting up. There's nothing you can do to protect me or anyone else.

Look, I mean, these are exactly the conversations we're having a one. The reason why I don't think blocking reading are enough is one, I don't think we've made mute powerful enough. It's spread all over the surface. You You can use it and then you gotta go find where you actually meet who these people are on their profile page. And that's just, it's not a it's a disaster. It just doesn't work in the same way that it should work in the same way that follow works, which is just the inverse event.

I noticed that now I get a notification that says you can't see this tweet because you meet this person, right before I would just see a weird reply and be like, Oh, it's one of those Exactly.

So there's also all this infrastructure that we have to fit So in order to, like pass those through in terms of what action you took, or what action someone else took to be transparent about, like what's happening on the network, the second. The second thing, that block is really interesting. I think it's my own view is it's wholly unsatisfying, because what you're doing is you're blocking someone, they get notification that you've blocked them, which may embolden them even more, which causes, you know, others around and ramifications from from the network. But also that person can log on to Twitter, and then look at your tweets, just on the public web, because we're Republic. So exactly. It doesn't feel as as rigorous and as durable as something like, making muet much stronger. But

I guess the challenge is, no matter what rule you put in place, people are going to harass you. If you're if you're engaging in public discourse, you know, if I go out in the street and yell out my opinion, somebody could get my face. If I get off Twitter, because I'm sick. I mean, look, you know, I'm sure you get away more than I do, especially as you know, the high profile probably getting in right now. Yeah, absolutely. Oh, me, too. God, I can only look. So the only thing I can do is, look, we're not on Twitter right now. We're on Joe Rogan's podcast, and they're still going to target you on Twitter, they're still gonna, I guarantee we're all over Reddit, the leftist probably railing on me the rights railing on you guys. So it's, it seems like even if you try everything in your power to make Twitter healthier and better, it's not going to change anything.

Sure about that? I'm not sure about that. Because one of the things that I do think is that just, I'm not in favor of a lot of this heavy handed banning, and a lot of the things that have been going on, particularly like a case like the MEGAN MURPHY case, but what I think that we are doing is we're, we're exploring the idea of civil discourse, where we're trying to figure out what's acceptable and what's not acceptable. And you're communicating about this on a very large scale. And it's putting that out there. And then people are discussing it, whether they agree or disagree when they vehemently defend you or, or hate you. They're discussing this. And this is I think, this is how these things change. And they change over long periods of time. Think about words that were commonplace just a few years ago, that you literally can't say anymore. Right now. There's so many of them that were extremely commonplace and not even thought to be offensive 10 years ago, that now you can get banned off appliances

for that's a good point to argue against banning people and to cease enforcing hate speech rules.

I agree with that as well. I think it's both thing.

Let me let me let me let me tell you something important. I was in the UK at an event for my name count, dank EULA, who I don't know if you've heard of Oh, sure. Yeah, Daniel was the guy who got charged and convicted of making a joke where he had his his pug do a Nazi salute. But I was there. And I was arguing that a certain white nationalist, had used racial slurs on YouTube. He has I don't want to name him. And some guy in the UK said, That's not true. He's never done that. And I said, You're crazy. Let me pull it up. Unfortunately, I don't know why. But when I did the Google search, nothing came up. What I did notice was at the bottom of the page, it said, due to UK law, certain things have been removed. So I don't know if it is exactly why I couldn't pull up a video proving or tweets or anything, because I think using these words gets stripped from the social platforms. I could not prove to this man, a century in the UK that this

could use a VPN and get around them.

Yeah, I mean, at the time, I was just like trying to pull it up. And I'm like, Ah, that's weird. So now you have someone who doesn't realize he's a fan of a bigot, because the law has restricted the speech. So there's a point to be made. If you I understand you want a healthy, like you want Twitter to grow, you need it to grow, the shareholders needed to grow that advertisers need to advertise. So you've got all these restrictions. But allowing people say these awful things, make sure we stay away from them. And it allows us to avoid certain people. And isn't it important to know that these people hold these beliefs if you get rid of them? You know, someone could walk into a business and you wouldn't even know that they were a neo Nazi. But if they were high profile, saying the things you'd be like, that's the guy at home, like

you're absolutely right. This is like one of my favorite sayings is that sunlight is the best disinfectant. And it's so so so true. Like one of the biggest problems with censorship is the fact that you push people underground and you don't know what's going on. And this is something I worry about. It's not that I don't worry about bad people. For these reasons. I also worry about driving people away from the platform and affecting their real lives. So like, we're trying to find this right balance and I hear you like, you may not think we're drawing the lines in the right place, and we get that feedback all the time. And we're always trying to find the right places. But I worry as much about like the underground and like being able to shine a light on these things is is anything else?

I think it's a cost benefit analysis and we have to constantly rehash it and do it. Like we we have the technology we have today. And we are looking at technologies which open up the aperture even more. And we all agree that a binary on or off is not the right answer and is not scalable, we have started getting into nuance within our enforcement. And we've also started getting into nuance with the presentation of of content. So, you know, one path might have been for some of your replies for us to just remove that those you know, offensive replies completely, we don't do that we hide it behind an interstitial to protect the original Twitter and and and also folks who don't want to see that they can still see everything, they just have to do one more tap. So that's one solution ranking is another solution. But as technology gets better, and we get better at applying to it, we have a lot more optionality. Whereas we don't, we don't have that as much today.

I feel like you know, I'm just gonna reiterate an earlier point, though, you know, if you recognize sunlight is the best disinfectant. You're it's like you're you're chasing after a goal that can never be met. If you want to, if you want to protect all speech, and they start banning certain individuals, you want to you want to increase the amount of healthy conversations, but you're banning some people, Well, how long until this group is now offended by that group? How long until you've banned everybody

I hear you, I don't believe a permanent ban promotes health. So I don't believe that, but we have to, we have to work with the technologies, tools and conditions that we that we have today. So and evolve over over time to where we can see examples, like this woman at the Westboro Baptist Church who was using Twitter every single day, to spread hate against the LGBTQIA community. And over time, we had, I think it was three or four folks on Twitter who would engage her every single day about what she was doing. And she actually left the church.

That's Michael Phelps. She's, she's amazing.

And she, she's now pulling her family out of that as well. And you could make the argument that if we banned that account early on, she would have never left the church, I completely hear that we we get it, it's just well, so

let's I just want to make sure we were advancing the conversation to not just gonna go back. So I'll just ask you this, have you considered allowing some of these people permanently banned back on with some restrictions, maybe you can only tweet twice per day, maybe you can't retweet or something to that effect. I

think we're very early in our thinking here. So we're open minded to how to do this. I think we agree philosophically that permanent bands are an extreme case scenario. And it shouldn't be one of our, you know, regular use tools in our tool chest. So how we do that, I think is something that we're actively talking about today.

Is there a timeline that we can so look, you know, I think

that would fix a lot of problems? Yes, I really do.

Like, I'm just curious, like, are you thinking like bands of a year or five years? 10 years? Like, I'm just curious, like, what is what is a reasonable ban in this kind of context?

Well, I think reasonably, someone should have to state their case as to why they want to be unbanned. Like someone should have to have a, like a well measured considerate response to what they did wrong. Do they agree with what they did wrong? Maybe perhaps saying why they don't think they did anything wrong? And you could review it from there.

I think, you know, one of the challenges, we have the benefit in English common law of hundreds of years of precedent and developing new rules and figuring out what works and doesn't Twitter's very different. So I think with the technology, I don't know, if you need permanent bans, or even or even suspensions at all, you could literally just, I mean, lock someone's account is essentially suspending them. But I again, I wouldn't, you know, claim to know anything about the things you go through. But what if you just restricted most of what they could say, you know, you blocked certain words in a certain dictionary, if someone's been if someone receives a greased Hill open, no, but but but think about this way. Is it better to permanently banned or better, but it's not good. It's not good even to think about it this way. Instead of being suspended for 72 hours, you get a dictionary block from hate speech words, right? Does that not make sense?

People just use coded language. That's what we see all the time. Yeah.

Well, good move. What do you think about perhaps, instead of what is it possible to have levels of Twitter, like a completely uncensored, unmoderated level of Twitter? And then you know, have like a radar and then have like a PG 13? I mean, I don't think that's a bad idea.

We have those levels in place today, but you don't really see them. One, we have a Not Safe For Work switch, which you can turn on or off.

Oh, really? Say for work switch, which I think you haven't off. Joe, do you think so?

Other things you're seeing you know, it's there. So we so we have that. And then as Richard pointed out earlier, you know, we have the timeline. We we started ranking the timeline about three years ago. We enable people today to turn that off completely. And see, you know, reverse cron of everything they follow you can you can imagine a world where that switch has a lot more power over more Over algorithms throughout more of the surface areas, you can imagine that so these are all the questions that are on the table. Yes, about timeline. And this is this is a challenging one. I don't know about timeline. Because first, we, we've decided that our priority right now is going to be on proactively enforcing a lot of this content specifically around anything that impacts physical safety, like, like Daxing. So,

right, but there's so many examples of what you guys not doing that.

I know. But that that's what we that's what we're seeing right now. That's that's a prioritization. But I think from your perspective, we think more in terms of milestones and the particular timeline, we're gonna move as fast as we can, but some of it's a function of our, of our infrastructure of the technology we have to we have to bring to bear. Do

you guys have conversations about trying to shift the public perception of having this left wing bias and maybe possibly addressing it? Yeah. I'm doing right now. Right. Yeah,

I went on the Sean Hannity show. I, you know, we how's that we brought ourselves before it was pretty a lot of sunlight. It was short. And he Well, it was short. And there weren't a lot of really tough questions and feedback as well. And yeah, I get it like, look, again, I'm also I'm from Missouri, my dad is Republican, he listened to Hannity, he listened to Rush Limbaugh, my mom was a Democrat. And I feel extremely fortunate that I was able to first see that spectrum, but also feel safe enough to express my own point of view. But when I go on someone like Hannity, I'm not talking to Hannity, I'm talking to people like my dad who listen to him, right. And I want to get across how we think and, and also that our thinking evolves. And here's the challenges we're seeing and like, this is our intent. This is what we're trying to protect. And we're going to make some mistakes along the way. And we're going to admit to him, we didn't admit to them in the past week and middle to a lot more over over the past three years. But, you know, I don't know any other way to address some of these issues at all. It all goes back to trust, like our one of our core operating principles is earning trust, how do we earn more trust? And I know there are people in the world who do not trust us at all in there are some people who trust us a little bit more, but this is the thing that we want to measure this the thing that we want to get better at. I

saw I had a conversation with I think Katie Hertzog No, no. Who was it? As the wrong person, you had a Twitter conversation with Kara Swisher wrong person, but someone's got to shut up. And, you know, I see that the left goes at us in the opposite direction, they want more, they want more bending, they want more, you know, restrictions, and then look at the right is saying less. Right. So I mean, in terms

of solving the problem. Tell us what that conversation was about.

I do want to summarize, because because my thing I was pointing out specifically was that you're being asked to do more in terms of controlling,

it wasn't just more but to be a lot more specific about what actions we've taken to promote more health on the platform, like what products did we change? What policies did we introduce in the past two years? So she was asking questions, every question she asked, she wanted me to be a lot more specific. And some of these things have something that is very specific, some are directional right now. Because like we have to prioritize, you know, the direction and I talked about, like, you know, we've decided that physical safety is going to be a priority for us. And to us, that means, like being a whole lot more proactive around things like Daxing.

So to suggestions, I guess I'm not going to imply that you have unlimited funding, but we did mention the peer review. Right, right. I mean, you had the you mentioned earlier with layoffs and retraction. Peer review, which we mentioned, but have you just considered opening an office even a small one for trust and safety in an area that's not predominantly blue? So that at least you have, like you can have some pushback? And is what is learned to code mean? And then they could tell you absolutely.

So that's a that's great feedback. And just so you know, the trust and safety team is also a global team. And the enforcement team is a global team. So it's not like people from California who are looking at everything, making decisions that are global. Now I hear your point about who trains them and the materials they have and all that. And like we have to think about that. And that's, that's one thing that Jack has really been pushing us to think about is how do we decentralize our workforce, because out of San Francisco, out of San Francisco with in particular, so this is something he's very focused on.

What about publishing evidence of wrongdoing and abandoned? So when people say, you know, what did Alex Jones really do? Maybe a lot of people didn't realize what you what you saw. And again, it's an issue of trust. Yeah,

I love this. Tim, I'm a lawyer. So by training, we're thinking of doing something called we call case studies. But essentially, like, this is our case law. This is what we use. And so on high profile cases, cases people ask us about like to actually publish this so that we can go through, you know, tweet by tweet just like this, because I think a lot of people just don't understand and they don't believe us when we're saying these things. So to put that out there so people can see and again, they may disagree with the calls that we're making, but we at least want them to see why we're making these calls. I think and that that I do want to do, I want to at least start that by the end of this year. So

I think, you know, ultimately, my main criticism stands that I don't see a solution to in that Twitter is an unelected, you know, unaccountable, as far as I'm concerned, when it comes to public discourse, you have rules that are very clearly at odds, as we discussed, I don't see a solution to that. And I think, in my opinion, we can have this kind of like, we've toned things down, we've had some interesting conversations. But ultimately, unless you're willing to allow people to just speak, speak entirely freely. You are, we have an unelected group with a near monopoly on public discourse in many capacities. And I understand it's not everything right, it is big too. And it's, you know, what I see is, you are going to dictate policy, whether you realize it or not, and that's going to terrify people, and it's going to make violence happen, it's going to make things worse, you know, the, I hate bringing up this example, on the on the rule for misgendering, because I'm actually I understand it, and I can agree with it to a certain extent. And I've you know, nothing but nothing but respect for the trans community. But I also recognize, we've seen an escalation in street violence, we see a continually disenfranchised large faction of individuals whose country, we then see only one of those factions banned, we then see a massive multinational billion dollar corporation with private and foreign investors. And it looks to me like if you hold, if you no foreign governments are trying to manipulate us there, I don't see a direct solution to that problem, that you do have political views, you do enforce them. And that means that Americans who are abiding by American rule are being excised from political discourse. And that's the future. That's it.

Yeah, we do have views on the approach. And again, like, we, we ground this in creating as much opportunity as possible for the largest number of people, right. That's where it starts. And where we are today, will certainly evolve, but like that, that is what we are trying to pace are our rules and judgments not. And I get that that's an ideology, I completely understand it. But we, we also have to, we also have to be free to experiment with solutions and experiment with evolving policy and putting something out there that might look right at the time and evolving. I'm not saying this is it but like, we, we look to research, we look to our experience and data on the platform and and we make a call. And if we get it wrong, we're we're going to admit it, and we're going to evolve

it. But I guess, do you, you understand my point? I understand the point that there are there are American citizens abiding by the law who have a right to speak and be involved in public discourse that you have decided aren't allowed to do.

And I think we've discussed, like, we we don't see that as a win. We see it as not promoting health, ultimately over time. Right. But

it's ultimately what is your priority? Do you have it prioritized in terms of what you've got what you guys would like to change?

I think Jack has said it a couple of times, but the first thing we're going to do is prioritize people's physical safety. Because that's gotta be understanding.

You already have done that pretty much, right? No, you do that more. We've

prioritized it. Okay, we're doing the work. I don't think companies like ours. Make the link enough. But what online and offline ramifications? What's

the main criticism? What's the main criticism? You guys? Is it censorship? That you guys experience? Is it censorship? Is a banning? Like, what is it? What is? What do you get the most? It depends on every

single person has a different criticism. So I don't think there's a universal opinion. I

mean, you just painted the picture, right? Between, like the left spectrum is asking for more Sure. On the right is asking for less. That's very simplified just for this country. But at a high level. Yeah, that's consistent. I mean,

my opinion would be as much as I don't, I don't like a lot of what people say about me what they do. The rules you've enforced on Twitter have done nothing to stop harassment towards me or anyone else. Right, I sort of had my Twitter, I mean, my Reddit is probably, you know, 50 messages from various, you know, far left and left wing subreddits, lying about me, calling me horrible names, quote, tweeting me, and these people are blocked, right. And I never used to block people because I thought it was silly, because I can get around it anyway. But I decided to at one point, because out of sight out of mind, if they see my tweets last, they'll probably interact with me last, but they do this. And they lie about what I believe they lie about what I stand for. And they're trying to destroy everything about me. And they do this to other people. I recognize that. So ultimately, I say, Well, what can you do? It's going to happen on one of these platforms, the internet is a thing, as they say, on the internet. Welcome to the internet. So you know, to me, I see Twitter, trying to enforce all these rules to maximize good and all you end up doing is stripping people from the platform, putting them in dark corners of the web where they get worse, and then you don't actually solve the relevant problem

or corner of the web, right? No, I'm not talking to you.

But there are dark corners of Reddit. There are alternatives. I mean, the internet isn't gonna go away and people have found alternatives. And here's the other thing that's really disconcerting. We can see a trend among all these different big Silicon Valley tech companies and they hold a similar view to you guys. They banned some ideology and they are creating a parallel society. You've got alternative social networks popping up that are taking the dregs of the of the mainstream and giving them a place to flourish, grow, make money. Now we're seeing people be banned from MasterCard from banned from PayPal, even banned from Chase Bank, because they all hold the same similar ideology to you. Oh, it's, you know, in some capacities. I don't know exactly why Chase does it. I assume it's because you'll get some activists who will lie when we were talking about. There have been a series of individuals banned from Chase Bank. accounts have been Yes, their accounts were closed one I think maybe the most notable might be Martina Mahkota. I don't know much about her. I follow her on Twitter and her tweets are typical, conservative fair. And she created a comic I think it's called Lady alchemy. She's a Trump supporter, and she got a notice that her business account was terminated. You then have Joe Biggs, who previously worked with Infowars. I don't know much about this. I didn't follow up. But he tweeted out, Chase has shattered my account. And then you have the new chairman of the proud boys and reggae. I forgot his last name TARIO or something. And so

he was really white. Oh, no, he's

he's Afro Cuban.

I know. That's what's the letter.

But you know, so what I see across the board, it's not just and this what I want to bring up before about perspective on these things. You guys are like, we're gonna do this one thing, and no snowflake blames itself for the avalanche. But now what do we have? We have conservatives being stripped from PayPal, we have certainly, I'll just say individuals from PayPal Patreon financing. So they set up alternatives. Now we're seeing people who have like, you mentioned Westboro Baptist Church, and she's been de radicalized by being on the platform. But now we have people who are being radicalized by being pushed into the dark corners. And they're building and they're getting, they're growing. And they're growing, because there's this, this idea that you can control this and you can't. You know, I think you mentioned earlier that there are studies showing and also counterparties, but people exposed to each other is better. I found something really interesting. And because I have most, whether or not people want to believe this, all of my friends are on the left. And some of them are even like socialists. And they're absolutely terrified to say to talk, because they know they'll get attacked by the people who call for censorship and try to get him fired. And when I talked to them, I was talking to a friend of mine in LA, and she said, Is there a reason to vote for Trump? And I explained a very simple thing about Trump supporters. This was back in 2016. I said, Oh, well, you know, you got a lot of people who are concerned about the free trade agreements, sending jobs overseas, so they don't know much about Trump, but they're gonna vote for him because he supported that and so did Bernie. And then the response is really, I didn't know that. And so you have this, this ever expanding narrative that Trump supporters are Nazis, and the mogga hat is the kicker, K hood, and a lot of this rhetoric, you know, emerges on Twitter. But when when a lot of these people are getting excised, then you can't actually meet these people and see that they're actually people. And they may be mean, they may be mean people. They may be awful people, but they're still people. And even if they have bad opinions, sometimes you actually, I think in most instances, you find the regular people. Well,

there's a part of the problem of calling for censorship and banning people and that it is sometimes effective, and that people don't want to be thought of as being racist, or in support of racism, or in supportive nationalism, or any of these horrible things. So you feel like if you support these bannings, you support positive discourse and a good society and all these different things. What you don't realize is, what you're saying is that this does create these dark corners of the web. And these other social media platforms evolve and have farm it mean when you're talking about bubbles. And about these, these group think bubbles. The worst kind of group think bubbles is a bunch of hateful people that get together and decide their posts. They've been persecuted. Instead of like we were talking about, with Megan Phelps having an opportunity to maybe reshape their views by having discourse with people who choose to or not choose to engage with them. Well, let's,

let's think about the the logical end of where this is all going. You want healthier conversation, so you're willing to get rid of some people who then feel persecuted and have no choice but to band together with others, MasterCard, Chase Patreon. They all do it, Facebook does it. They're growing, these platforms are growing, they're getting more users, they're expanding, they're showing up in real life, and they're there. You know, even if these people who are banned aren't the neo Nazi evil, they're just regular people who have banded together that forms a parallel finance system, a parallel economy, you've got Patreon alternatives emerging where people are saying, you know, we reject you. And now we're on a platform where people say the most ridiculous things. Now they have money and normalizes that as well, that's also that's what I mean by a parallel society. To them. Everything they're doing is just and righteous and you can't stop them

anymore. And it develops hate for the opposing viewpoint, you start hating people that are progressive, because these are the people that like you and I have talked about the data and society report that labeled us as alt right adjacent or whatever now more fake news coming out, right? Well connected because you and I have talked to people that are on the right or far right that somehow or another we're secretly far right and that there's this influence network of people together. And this fake Well, it's, it's a schizophrenic connection. It's one of those weird things where people draw the circle Oh, you talked to this guy and this guy to talk to that guy, therefore, you know that guy. Well, so

So here's an expanded part of this problem. So this probably familiar but a group called data in society published what's entirely fake report, labeling at one alt right adjacent to wherever they want to call it. YouTube channels included Joe Rogan. And me. It's fake. But you know what a couple of dozen news outlets wrote about it as if it was fact you believe the proud boys were labeled as FBI by the FBI as extremists when they actually weren't, it was a sheriff's report from someone not affiliate with the FBI. But they are activists within Media who have an agenda. And we saw this with learn to code. It was an NBC reporter who very clearly is in left wing identitarian writing a story for NBC than your average american sees that NBC story thinks it's factual, then everyone talks about it, then your people hear about it, then you start banning people. So you know, to drive the point home, the snowflake won't blame itself for the avalanche, you guys are doing what you think is right. So is Facebook, YouTube, Patreon, all these all these platforms, and it's all going to result in one thing, it's going to result in groups like Patriot prayer and the proud boys saying I refuse to back down showing up, it's gonna result in Antifa showing up, it's going to result in more extremism. You've got an Antifa count that published the home addresses and phone numbers that hasn't been banned. That's going to further like show conservatives that the policing is asymmetrical, whether you know it is or isn't. And I think the only outcome to this, on the current course of action is like insurgency, we've seen people planting bombs and using try to blow up a statue, we saw someone plant a bomb at a police station in Eugene, Oregon, two weeks before that a guy showed up with a gun and fire two rounds at a cop wearing a smash the patriarchy and shelter. So, you know, so that happens. Then a week later, they say you killed our comrades. And a week later a bomb was planted. I don't believe it's coincidence. Maybe it is. But, you know, I lived in New York, I got out too many people knew who I was. And there was people sending me emails with threats. And I'm like this is escalating. You know, we've seen throughout the past two years with Trump we've seen Breitbart has a list of 640 instances of Trump supporters being physically attacked or harassed in some way. There was a story the other day about an 81 year old man who was attacked, and it seems like everything's flowing in one direction. And nobody wants to take responsibility and say, maybe we're doing something wrong. Right. That's why That's why I brought up earlier regulation is, in my opinion, inevitable.

I mean, I don't think it's going to be the responsibility of any one company, we have a desire to be clear that we have a desire to promote health in in public conversation. And as we've said, like I don't think over time, a permanent ban promotes health. I don't but we have, we have to we have to get there. There are exceptions to the rule, of course, but like, we, we just have work to do. And I the benefit of conversations like this is we're talking about it more, but the people will naturally call us out like you got to you got to show it as well.

Do you fear regulation?

I don't, I don't fear regulation. If if we're talking about regulation in the government intervention in the job of if a regulator job is to protect the individual, and make sure that they level the playing field, and they're not pushed by any particular special interests, like companies like ours, who might, you know, work with irregular to protect our own interest that I think is incorrect. I agree that we should have an agency that can help us protect the protect the individual and level the playing field. So I think oftentimes, companies see themselves as reacting to regulation. And I think we need to take more of an education role. So I don't fear it. I want to make sure that we're educating regulators on what's possible, what we're seeing and where we could go.

When you say educating regulators that's initiating a regulation. I mean, you mean,

not necessarily. I mean, we might just be taught

cating regulators, who are these regulators.

These are folks who, who might be tasked with coming up with a proposal for particular legislation or, or laws, to present to legislators. So it's making sure that we are educating to the best of our ability, this is what we are, this is what we see, this is where technology is going. And do

you think you can hold off regulation, though? Do you think that by these approaches, and by being proactive, and by taking a standard, perhaps offering up a road to redemption to these people, and making clear distinctions between what you're what you're allowing what you're not allowing you can hold off regulation? Or do you disagree with what he's saying about regulator? I

don't believe that should be our goal is to hold off regulation, I believe we should be we should participate like any other citizen, whether it be a corporate citizen or an individual citizen, in helping to guide the right regulation.

So are you familiar and I could be wrong on this? Because it's been like 15 years since I've done this. Are you familiar with the Clean Water Restoration Act? At all? I don't expect anybody it's a very specific thing. So it was at some point in like the early 70s There was a river in Ohio and again, I couldn't Iran has been 15 years I used to work for an environmental organization started on fire. And what was typically told to us was that all of these different companies said we're doing the right thing. But this like, as I mentioned, the snowflake doesn't blame itself. So over time, the river was so polluted, it became sludge and lit on fire. And so someone said, if all of these companies think they're doing the right thing, and they've all just contributed to this nightmare, we need to tell them blanket regulation. And so what I see with these companies like banking institutions, public discourse platforms, video distribution, I actually, I'm really worried about what regulation will look like, because I think the government is going to, you know, screw everything up. But I think there's going to be a recoil of first I think the Republicans, because I watched the testimony you had in Congress, and I thought they had no idea what they're talking about, nor did they care. There was like a couple of people who made good points, but for the most part, they were like, whatever. And they asked about Russia and stuff. So they have no idea what's going on. But there will come a time, when, you know, for instance, one of the one of the great things they brought up was that by default, when someone in DC signs up, they see way more Democrats than Republicans. Right? You remember that when you just about? Yeah. So well, that there's an issue. And I don't think I believe you, when you say it's algorithmic that these are, you know, prominent individuals, so they get automatically recommended. But then there, you know, so again, the solution to that, like, how do you regulate a programmer to create an algorithm to solve that problem is crazy. You're regulating someone to invent technology. But I feel like there'll be a backlash when too many. Right now we're seeing the reason one of the reasons we're having this conversation is that conservatives feel like they're being persecuted and repressed. So then it's going to escalate from it's not going to stop with these conversations.

And so that we've been having a lot of talks about this, particularly around algorithms. And one of the things that we're really focused on is not just fairness and outcomes, but also explainability of algorithms. And I know, Jack, you, you love this stuff. So I don't know if you want to talk a little bit about our work there. Yeah, I

mean, we. So there's two fields of research within artificial intelligence that are rather new, but I think really impactful for our industry. One is fairness and ml. So what fairness and machine learning and deep learning. So looking at everything from what dataset is fed to an algorithm, sort of like the training data set, all the way to how the algorithm actually behaves on that on that data set, making sure that it does not develop bias over the long term longevity of the algorithms use case. So that's one area that we want to lead in. And we've been working with some of the leading researchers in the industry to do that. Because the reality is a lot of this human judgment is moving algorithms. And the second issue with it moving algorithms is algorithms today can't necessarily explain the decision making criteria that they use. So they can't explain in the way that you make a decision, you explain why you make that decision. algorithms today are not being programmed in such a way that they can even explain that you may wear an Apple Watch, for instance, it might tell you to stand every now and then. Right now, those algorithms can't explain why why they're doing that, right. And that that's a bad example, because it does it every every 15 minutes. But as we offload more and more of these decisions, both internally and also individually to watches and to cars and whatnot, there's no, there's no ability right now for that algorithm to actually go through and list out the criteria used to make that decision. So this is another area that we'd like to get really good at, if we want to continue to be transparent around our actions, because a lot of these things are just black boxes, and they're being built in that way. Because there's been no research into like, Well, how do we get these algorithms to explain what their decision is, like motion hasn't been asked? My

fear is you It's technology that you need to build. But the public discourse is there. We know that foreign governments are doing this. We know that democratic operatives in Alabama did this. And so I imagine that, you know, with Donald Trump, I, you know, he talked about an executive order for free speech on college campuses. So the chattering is here, someone's going to take a sledgehammer to Twitter, to Facebook, to YouTube and just be like, for not understanding the technology behind it. Not willing to give you the benefit, but the benefit of the doubt and just saying, I don't care why you're doing it, we're mad. You know what I mean? And then pass some bills. And then it's over. Again, clarifying. I think you guys are biased. And I think what you're doing is dangerous. But I think that doesn't matter. It doesn't matter what you think is right. It matters that all of these companies are doing similar things. And it's and it's and it's already terrifying people. I mean, look when when I saw somebody got banned from their bank account, that's terrifying. And Pay Pal has done this for a long time. You know, that seems

like more egregious than getting banned from any social justice or social media platform that that seems to me to be worthy of. A boycott,

patriot. Patreon issued a statement about a man I believe his name is Robert Spencer. And they said MasterCard instructed us to ban him. And you know, you'd all say this to me mentioning Chase Pay Pal MasterCard terrifies me. I'm on the Joe Rogan podcast right now calling out these big companies in defiance. And we've already seen,

I would like to know all the specifics of why they chose to do that. And I would hope that they would release some sort of a statement explaining why they chose to do that. Maybe there's something we don't know, there was

there was a reporter. And I kept getting this wrong cuz I didn't follow it very much with big league politics, who said that after reporting on PayPal negatively, they banned him. That's terrifying. So less

reporting on it in what way like reporting on the Sargon of Akkad issue? No,

apparently is a journalist. He wrote about something bad Pay Pal did big league politics is conservative. And so all of a sudden, he got a notification that they can't tell him why but he's gone. So I see these big tech monopolies. I see YouTube, Facebook, Twitter, I see Pay Pal MasterCard, and they're doing it. And they all say they're doing the right thing. But all of these little things they're doing are adding up to something nightmarish. And some some right legislator is going to show up and in a matter of time with a sledgehammer and just, he's gonna whack your algorithm. Well, it's

really the same stupid logic where I was talking about where, you know, Gavin was saying punch people when you punch people. It doesn't end there. ban them. Ban doesn't end there doesn't end there. Yeah, you have to realize also Twitter's how old now? 11 years old. 13 years old.

1313 years old.

Well, 13 years from now, what are the odds that there's not going to be something else just like it? Well, pretty slim. Yeah, we do. A million No,

but let's let's let's talk about the incestuous relationship that a lot of these journalists have in defending the policies you guys push. Gab it was was was a study was done. I talked about this last time where they found 5% of the tweet of the I don't say tweets, but the posts on gab or hate speech compared to Twitter's like 2.4. So it's a marginal increase at gab is called the white supremacy network. Of course, you go on it and yeah, absolutely exists. They say that synagogue shooter Oh, who was a gab user, he was a Twitter user, too. He posted on Twitter all the time. So why the media is targeting. It's such a crazy reality is octave narrowed. When when the Guardian, I believe was the Daily Mail called count dank, EULA Nazi hate criminal. It's really made a joke on YouTube. And he's been he was arrested. I think got every day, we have the First Amendment in this

country. Well, that was a cover of a newspaper. That was because he got a job somewhere they get he got fired. For that

he got kicked off the show. Wow. Yeah. So you have to let me let me. Let me ask you another thing. Do you guys, do you guys take the advice of the Southern Poverty Law Center? Do we take the advice of like, so it's widely circulated? The SPLC lobbies various social platforms to ban certain people? They advise? It's been reported they advised YouTube as the anti Defamation League, do you do use them in your decision making process it rule development? We're

very aware of flaws with certain of their research. And we're very careful about who we take advice from,

but do you take advice from them?

I think that they have certainly reached out to our team members, but there's certainly nothing definitive that we take from them. We don't

take action, you never take an action based on the information received from them. So the reason I bring them up specifically is that they're cited often. You know, in the United States, there's other groups like hope, not hate in the UK. And now they're all going to point their, you know, figurative guns at me for saying this. But the Southern Poverty Law Center, wrote an article where they claimed I went to Iran for a holocaust deniers conference. And I've never been to Iran. And their evidence was this guy found an archived website from a Holocaust denier with my name on it. And that was their proof. And there are people who have been labeled, you know, extremists by this organization that have been you, Sam Harris. Sam Harris was started was

Yeah. I mean, it didn't they lose a big lawsuit around this. They settling? Yeah.

So again, like not not to imply that you guys do use it, but I asked specifically, because it's been reported other organizations do. So we have activist organizations, we have journalists that I can attest, are absolutely activists, because I've worked for I worked for Vice, I worked for fusion, I was told it implicitly, not explicitly to lie to side with the audience, as it were, I've seen the the narratives they push. And I've had conversations with people that I'm not going to I'm going to keep relatively off the record journalists who are terrified because they said the narrative is real. Right. One journalist in particular said that he had really had evidence of, you know, essentially, he had reasonably if there was wrongdoing, but if he talks about it, he could lose his job. And there there was a journalist who reported to me that data in society admitted the report was was was was incorrect. And now you've got organizations lobbying for terminating Joe and I, because of this stuff. So this, this narrative persists. Then you see all the actions I mentioned before, and all the organizations saying we're doing the right thing, and I gotta say, like we're living in. I mean, I feel like we're looking at the doorway to the nightmare dystopia of AI.

I just want to clarify, like, I don't, I don't know if we're going around saying we're, we're necessarily doing the right thing. We're saying why we're doing what we're doing. Right. That's what we need to get better at. And I I don't want to hide behind what we believe is like the right thing we have to clearly rationalize why we're making the decision we're making and more of that that's that to me, is the prevention from this snowflake avalanche metaphor.

Well, but but I think it's just obvious to point out again, I said this before we can have the calm conversation I can understand you. But from from where I'm sitting, you hold a vastly different ideology than I do. And you have substantially more power in controlling my government that terrifies me. And what's what makes it worse is that a Saudi prince owns, as was reported, that Saudi prince owns a portion of that company. So I'm sitting here like, just a little American, can't do anything to stop it. I'm just watching this unaccountable machine churn away, and you're just one snowflake in an avalanche, all these other companies are as well. And I'm like, well, here we go, this is gonna be a ride. They

just said that Saudi prince doesn't have any influence. What am

I supposed to trust that that's, that's the issue, right? I'm not trying to insinuate he's showing up to your meetings and telling you what to do. But when someone dumps a billion dollars in your company, I think it's silly to imply that they don't at least have some influence. But But regardless,

and unlike the internet, within a company like ours, you don't necessarily see the protocol, you don't see the, the processes, and that's an area where we can do a lot more, I

guess, you know, beat it over the head a million times, it'd be the dead horse. I think ultimately, yeah, I get what you're doing. I think it's wrong. I think it's terrifying. And I think we're looking, we're slow. We're on the avalanche already. It's happened. And we're heading down to this nightmare scenario of a future where it terrifies me when I see people who claim to be supporting liberal ideology, burning signs that say free speech, threatening violence against other people. You have these journalists who do the same thing. They accuse everybody of being a Nazi, everybody of being a fascist Joe Rogan. And you're like, you're like a socialist. As far as I know. You're like, ubi proponent? You know,

I wouldn't necessarily say I'm a very, I'm

being facetious. I'm

very liberal. And except for a second amendment, that's probably the only thing that I disagree with a lot of liberals. And then

you see what the media says about everybody. You see how they call Jordan Peterson all day and night. All right, the alt right hates him. And this narrative is used to strip people of their income to to remove them from public discourse. And it was foolish

because in the ultimately, upon examination, like you're saying that sunlight is the best disinfectant. Absolutely. Upon examination, you realize that this is not true at all, and that these people look foolish, like the data and society article.

No, no, no. All these organizations publish that as fact, without looking at any data.

Maybe some did. But no, dozens. But yeah, and no, no, no, they're still talking about millions and millions of people who are these people that are still citing it, Guardian will clamp down and start yelling, shame. But so so so look foolish,

we now have, and this makes things muddier, as we now have a guy who's claiming that he did this, you're gonna love this, there's a guy claiming that the 81 accounts listed on this thing is all right, have been done no longer being recommended on YouTube. And so I looked at the statistics for various people on this channel, because first of all, my channel is doing great, my recommendations are way up, as are yours, a lot of people are growing. And I did a comparison, like, subscribers are up views are up, what's this guy claiming. And apparently, he did a big sampling of videos, where he for some reason, thought you Joe Rogan were 12% of all videos in this network. And then when when his data stopped working, he claimed that everything stopped. So he actually produced a graph of primarily your channel. And then when his system stopped working, he published that and it was picked up by CNET. And now you have people claiming the alt right has been banned from from YouTube. And it's more fake news based off fake news based off fake news.

I don't understand what you're saying.

So basically, there's a guy claiming that because of data in society, we have been stripped of recommendations on YouTube that you don't

I'll tell you one thing that is true, though we don't trend. Like Alex Jones was saying, like, the video we did got 9 million views, but it's not trending. And I said, Well, it's because my videos never trend. They just don't trend. Well here. But I think it's probably because of the language that's used. I think that's that's part of the issue. It's a subject matter in language I think they have they have a bias against swearing and you know, extreme topics and subjects if I

don't I don't think that's true, because you've had like, late night TV hosts to talk about really messed up things.

They don't swear though, it's not it's not a matter of and what they talked about whether that's messed up in comparison to what we talked about, it's probably pretty different.

You know, I'm in I'm, I'm fairly resigned to this future happening, no matter what we do about it. And so I bought a van and I'm gonna convert it to a cruise. Well, I'm kind of into a workstation right?

You're gonna be a prepper bro. No, no, no, no, no, no, no, no, no.

First of all, I will say it's hilarious to me like that people have band aids they never used but they don't store like at least one emergency like food supply. It's like you never use band aids. Why do you have them? But no, I do I see this every day. It was a couple of years ago I said wow, I see what's happening on social media. We're gonna see violence boom, violence happened. I said, Oh, it's gonna escalate someone's gonna kill boom, Charlottesville happened. And it's like I've there have been statements from foreign security advisors, international security experts saying we're facing down high probability of civil war. And I know it sounds crazy. It's not gonna look like what you think it looks like. It may not be as extreme as it wasn't 1800s. But this was, I think, I think it was in the Atlantic, where they surveyed something like 10 different international security experts who said based on what the platforms are doing based on how the people are responding. One guy said it was like 90 percent chance, but the average was really high.

Well, let's, let's look outside of the idea of physical war. And let's look at the war of information, what we're talking about what's happening with foreign entities invading social media platforms and trying to influence our elections and our democracy. That is a war of information. That is that war is already going on. If you're looking at something like data and society, that's sort of an act of war in that regard, right. It's an information war,

an attempt to to lie to people, it's a ship out there, their ideological opponents.

And it's also one of the women who wrote that said that it's been proven over and over again, the D platforming is an effective way to silence and then called for us to be banned. Yeah. What's what's kind of hilarious? I don't think she was saying that we should be banned for I don't think she said, Well, she should be she said

something to the effect of YouTube has to take action to prevent this from you know,

well, you know, when people see someone saying things that they don't agree with, it's very important for people to understand where silencing people leads to. And I don't think they do I think people have these very simplistic ideologies and these very, very narrow minded perceptions of what is good and what is wrong. And I think, and I've been saying this over and over again, but I think it's one of the most important things to state people need to learn to be reasonable. They need to be learned to be reasonable and civil discourse. civil discourse is extremely important. And think over the long term. Yes, they understand it. You're playing chess. Yeah. We did three hours and 30 minutes, then we nobody had a P. Amazing, proud of all of you.

We did start a little late. Yeah, we're like 315. I mean, I guess the last thing I could say is I don't think I think we had a good conversation. I think we did I honestly, I don't think we've solved anything. I don't think there's any any, do you think we could do this again,

like six months and see where you guys are at in terms of like, what I think is important is the road to redemption. I think that would open up a lot of doors for a lot of people to appreciate you,

we're gonna need more than six months.

Here, here's the scary thing, the information travels faster than you can, right? Yeah, that's the point I was making. The our culture is going to evolve faster than you can catch up to that problem, because there's a problem. And I don't want to do technology took a big leap. Twitter existed, the internet existed. Now we're all talking so quickly, you can't actually solve the problem before the people get outraged by it. So

no one could I mean, there was an early phrase on the internet, by some of the earliest internet engineers, and designers, which is code is law. And a lot of a lot of what companies like ours and startups and random folks who are individuals who are contributing to the internet will change parts of society in some for the positive and some for the negative. And the most, I think the most important thing that we need to do is to, as Victor said, shine up, punch a light on it, make sure that people know where we stand and where we're trying to go, and what bridges we might need to build from our current state to the future state and, and be open about the fact that like, we're not going to and this is, to your other point, we're not going to get to a perfect answer here. Like it's, it's just going to be steps and steps and steps and steps. And the what we need to build is agility, what we need to build as an ability to experiment very, very quickly and take in all these feedback loops that we get some feedback loops like this, within the numbers itself, and then integrate them much faster. What's wrong

with with the jury system on Twitter? Why wouldn't that work?

I don't know why I want to work on I'm not saying we wouldn't test that. Yeah, like we're testing our scope. And I don't have a reason, a compelling reason why we wouldn't do it within Twitter, either. I don't. So we likely will. But, you know, again, we were a company of so many resources, finite resources, finite people, and we need to prioritize, and we've decided you may disagree with this decision. But we've decided that physical safety and the admission of off platform ramifications is critical for us. And we need to be able to be a lot more proactive in our enforcement, which will lead to stronger answers. And we want to we want to focus on the physical safety aspect. And Daxing is a perfect example that has patterns that are recognizable, and then we can move on,

I hear it. And I just feel like, you know, the conclusion I can come to in the conversation is you're going to do what you think needs to be done. I think what you're doing is wrong. And ultimately, nothing's gonna change. I get it, you're gonna you're going to try new technologies, you're going to try and do new systems. From from where I see it. I think you have an ideology, diametrically opposed to mine. I mean, not to an extreme degree. I think there are people who are more like I'm not conservative. There are a lot of people who are who are probably think, you know, I'll say this to you or a symbol for a lot of them and so I can definitely respect you having a conversation. There are so many different companies that do things that piss people off. You're sitting here right now I'm sure there's a ton of conservatives who are pointing all of their anger and you because you are here But you know, ultimately, I just feel like, I don't think anything's gonna change. I think you're on your path, you know what you need to do, and you're trying to justify it. And I'm looking at what Twitter is doing as very wrong. And it's, it's, it's it's oppressive and ideologically driven. And I'm trying to justify why you shouldn't do it, but nothing's going to change.

My intention is to build a platform that gives as many people as possible opportunity to freely express themselves.

Some people believe the United States has already done that. And Twitter is now going against what the US has developed over hundreds of years.

This is a platform. I mean, the United States doesn't have a platform to do that Twitter is when you're talking about the internet, the United States, if they want to come up with the United States, Twitter, like a solution alternative that the government runs, and they use it use free speech to govern that. Good luck. Good luck with that. Well, it's

a huge, it's a huge challenge. And also, I

recognize not just, you know, almost insurmountable. I mean, they have the dummies that are in charge of the United States government. This

is why I said regulation two is scary. Yeah, you know, this slide sheets, a terrible idea. But so but you know, and I think it's important to point out too, that a lot of people don't realize, you guys have to contend with profits, you have to be able to make money to pay your staff, there's no like, you don't get free money to run your company. So aside from the fact that you have advertisers want to be on the platform, I imagine a lot of these companies are enforcing hate speech policies, because advertisers don't want to be associated with certain things. So that creates, you know, through advertisement, cultural restrictions. That's 100%.

The problem, right, 100% of the problem with most of these platforms, including YouTube. Absolutely. Yeah, I mean, when the PewDiePie thing happened, and all of these, you know, restrictions came down on on advertising and content creators, that's where it comes from. It all comes from from money. It's

why all

those good, just to be clear, those can be segmented, as well. Secondly, advertisers can choose where they want to where they want to be placed, certainly,

but the platform recognizes there's a huge blowback, and they're losing money.

I mean, look at the pedo scandal that just happened on YouTube. It was people posting comments with timestamps, they weren't even breaking the rules. And advertisers pull up the platform, and YouTube didn't realize because they weren't breaking the rules. They're just creepy dudes. So be people.

Yeah. Also, they were putting comments. And so one of the most preposterous responses to that was that content creators is going to be responsible for their comments. Well, they turn them off. Well, the problem was this legit people like me is that I put out a lot of content. And there's millions of views. And it's impossible to moderate the comments, and we don't moderate them at all

right, but YouTube banned only on videos with minors. So they deleted all comments on videos

with my videos where they say youth, but you know, I'm saying if you put a YouTube video on, you have a bunch of people that say a bunch of racist things in your YouTube comments, you could be held responsible and get a fuck, no, no,

you do clarify that. They clarify that what recently they said that afterwards.

But the first initial statement was that you're gonna be responsible for your comments. And then I said, it's only my bowl like Philip DeFranco. And a lot of people freaked out and then they qualify them. But so

the reason I bring that up is just because there's going to be things that even if you segment your advertisers from look, you know, I pointed out I think the the Democrats are in a really dangerous position because outrage culture, although it exists in all factions, is predominantly on one faction. And so when Trump comes out and says something really offensive, you know, grab them by the, you know, I'm talking about the Trump supporters laugh, they bought T shirts that said it, the people on the left the Democrat types, they got angry. So what happens now you see Bernie Sanders who's being dragged, the media is looking for blood, and they're desperate, they're laying people off, they're dying, and they will do whatever it takes to get those clicks. There wasn't like, you know, is it have to do with Twitter, though, it has to do with the fact that someone's going to find something on your platform, and they're gonna call up your advertiser and say, Look what Twitter's doing and you're gonna be like, we have no idea and too bad and canceled all ads, your money's dried up. And so that the reason I bring that up as I recognize, Twitter, YouTube, Facebook, as other platforms are worried money has to come from somewhere to pay people. So you also have to realize you've got the press that salivating looking for that juicy story where they can accuse you of wrongdoing because it'll get them clicks, they'll make money. And that means, even though YouTube did nothing wrong with these comments, it was just a creepy group of people who didn't break the rules, who figured out how to manipulate the system YouTube ate, like, you had to take the take that one the advertisers pulled out YouTube lost money. So you did then panics, sledgehammers comments, just wipes them out. That could have been anybody, right? We're in a really dangerous time with

also in their defense, so they have to deal with that. I mean, they have a bunch of pedophiles that are posting comments now. I mean, what do you do about that? What do you what other than hire millions of people to moderate every single video that's put on YouTube, which is almost impossible.

The point I'm trying to break bring up is that even if Twitter wanted to say you know what, we're going to have free speech what happens advertisers rock later, even if you segment it, they're gonna be threatened by it. And so the restrictions are going to come from whether or not you can make money doing it.

I don't know about that. I don't know. I think that that is changing and I think that is changing primarily only because of the internet, if you look at what was acceptable in terms of people discussing, that would get advertisement, it was network television standards. Now that's changing. I mean, there's there's going to be there's ads on a lot of videos that I put out that have pretty extreme content. It's because advertisers are changing their perspective. I don't think so. They're shifting their 100% shifting. That's why this, this podcast has ads. Sure,

sure. I mean, I don't think it's to the point where everyone's lost all ads. But look, you think George Carlin would be allowed to do his bit today? Yes.

No way. No, come on, man. Right, you would be able to do it. Listen, there's stuff like that on Netflix specials that are out right now. Things are changing. It's just in the process of this transformation, where people are understanding that because of the internet. First, if you look at late night conversations, how about Cole bear saying that President Trump has Putin stick in his mouth? How about him saying that on television? Do you really think that would have been done 10 years ago? It wouldn't have been well, 15 years ago, 20 Impossible. Not possible. But you standards are changing because of the internet. So things that were impossible to say on network television just 10 years ago, you can say that Kevin? Kevin

Hart lost his Oscar hosting gig 10 years ago, right.

But do you know why he lost he lost it because people were complaining, right? Because people who were activists were complaining that he had said some homophobic things and they had subsequently apologized for before they ever listened that count count. Dank EULA is a comedian. Okay, look, you were to discuss this, I'm with you. And I understand what you're saying. But I'm a comedian, and I understand where things are going. The demise of free speech is greatly exaggerated. That's what I'm saying. I'm saying there's a lot of people out there that are complaining. But the problem is not necessarily that there's so many people that are complaining, the problem is that people are reacting to those complaints, right? The vast majority of the population is recognizing that there is an evolution of free speech that's occurring in our culture and in all cultures around the world. But this is a slow process. And when you're in the middle of it, it's so almost like evolution, while you're in the middle of it, you don't think anything is happening, but it's fucking happening. So

I agree with you. I agree with you that the majority of people are like, that's funny, I don't care. But the minority is kind of dictating things right now, for now.

They're not even dictating things. They're just making a lot of that noise is having an effect. That's what data in society was an attempt at. Right? I don't think it was effective. That's why we're still here. We're talking right now. It was one attack. But I mean, many of them and there's hundreds of articles that are written about all sorts of things that are inaccurate. And

some people have been eating bank accounts, and some people have been kicked out. Yes.

This is why it's important to have this conversation right conversations like that. Well.

So here's what I'll say. I just I cross my fingers and I wait for when you implement blockchain technology, bro. Well, the van is going to be a mobile production studio, so I can travel around when things are getting great. A lot of water. Not well. I'm putting a bandaid, I'm putting a shower in it. Okay. It's gonna be like a computer and monitors, and I'm gonna be able to do video so I can travel around when everything's happening. But But I just made this up. I want to see the blockchain version of Twitter where it's exists. That's what I want to see it's gonna happen

whether we like it or not vigia. Any last thoughts?

No, I just want to thank you. Joseph has been great. And Tim, thanks for your feedback. You were always listening. And I've learned a lot today.

Thank you. I really appreciate you guys. Thank you, Jack. Thank you. Any last things? No,

I think we've said it all.

That's a wrap folks. No more ear beatings. Good night, everybody.

That was awesome. Thank you. Thank you.

Thanks for Chuck for talking. I really do appreciate it. Hey,

could you I follow up on a couple of things because they worry me. The you mentioned an Antifa account that docs policeman Can you please just send that over me

bit.li/antifa tweet BIT

dot L y slash Antifa tweet and then would you DM me I'll follow you would you DM me the the accounts that you said had threatened you know

I believe in minimizing harm and if I so when Patreon

well how about this I won't take action on it but I want to understand why you didn't take action on them and I can't learn from that unless you so

when Lauren southern got banned from Patreon a lot of people were there was

everybody out. This is streaming and it's frozen

Wow.

But not Okay